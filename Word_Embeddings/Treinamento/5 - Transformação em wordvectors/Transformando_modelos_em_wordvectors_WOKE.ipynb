{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "39fvrVJKVLEV",
        "fyPYocyPb3_t"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Link para melhor visualização do Notebook em seu ambiente de execução: [Notebook Colab](https://colab.research.google.com/drive/151Fsw7xjtCZVNzljrqH2fifab-MzdWII?usp=sharing)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Notebook desenvolvido para transformar os modelos das séries temporais em wordvectors (objeto mais leve que o modelo propriamente dito e que é usado de fato para realização de operações como analogias, vizinhos mais próximos, similaridade, etc).\n",
        "\n",
        "Este notebook foi pensado para tornar os arquivos dos modelos mais leves, principalmente, para o programa de visualização de resultados não precisar baixar arquivos grandes e diminuir o espaço ocupado na RAM quando estes forem carregados."
      ],
      "metadata": {
        "id": "zfV1BRgchzwe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heg3BJcoib5W",
        "outputId": "21f1af2b-ddc2-4cb3-a872-8e6e6923cdeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criar pasta para armazenar wordvectors e armazená-los"
      ],
      "metadata": {
        "id": "Wce0m7aCVG5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Seleçao de pasta (... - Treinamento - Com RE - Tipo de treino das séries temporais - Modelo X) que se deseja transformar os arquivos \".model\" para \".wordvectors\"\n",
        "pasta = r'/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Word Embeddings/Treinamento do nosso modelo/Treinamento com temporalização/Todas 2003 - 2006/Com RE/Treinamento temporal/Modelo 2'\n",
        "\n",
        "caminho_modelos = [os.path.join(pasta,m) for m in os.listdir(pasta) if m.endswith('.model')]\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "pasta_kv = os.path.join(pasta,'WordVectors')\n",
        "if not os.path.exists(pasta_kv):\n",
        "  os.makedirs(pasta_kv)\n",
        "\n",
        "for i,caminho_modelo in enumerate(caminho_modelos):\n",
        "  print(i+1)\n",
        "  word_vectors = Word2Vec.load(caminho_modelo).wv\n",
        "  word_vectors.save(os.path.join(pasta_kv,os.path.basename(caminho_modelo).replace('.model','.wordvectors')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFhtGvMlioFN",
        "outputId": "df050a37-ff1d-4e6c-c227-9f3e3b1ce20d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pasta = r'/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Word Embeddings/Treinamento do nosso modelo/Treinamento com temporalização/Todas 2003 - 2006/Com RE/Treinamento temporal/Modelo 3'\n",
        "\n",
        "caminho_modelos = [os.path.join(pasta,m) for m in os.listdir(pasta) if m.endswith('.model')]\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "pasta_kv = os.path.join(pasta,'WordVectors')\n",
        "if not os.path.exists(pasta_kv):\n",
        "  os.makedirs(pasta_kv)\n",
        "\n",
        "for i,caminho_modelo in enumerate(caminho_modelos):\n",
        "  print(i+1)\n",
        "  word_vectors = Word2Vec.load(caminho_modelo).wv\n",
        "  word_vectors.save(os.path.join(pasta_kv,os.path.basename(caminho_modelo).replace('.model','.wordvectors')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "melSt4QOhhKE",
        "outputId": "744feb5a-e6ec-4922-d268-f855d9f0f151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pasta = r'/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Word Embeddings/Treinamento do nosso modelo/Treinamento com temporalização/Todas 2003 - 2006/Com RE/Treinamento temporal/Modelo 4'\n",
        "\n",
        "caminho_modelos = [os.path.join(pasta,m) for m in os.listdir(pasta) if m.endswith('.model')]\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "pasta_kv = os.path.join(pasta,'WordVectors')\n",
        "if not os.path.exists(pasta_kv):\n",
        "  os.makedirs(pasta_kv)\n",
        "\n",
        "for i,caminho_modelo in enumerate(caminho_modelos):\n",
        "  print(i+1)\n",
        "  word_vectors = Word2Vec.load(caminho_modelo).wv\n",
        "  word_vectors.save(os.path.join(pasta_kv,os.path.basename(caminho_modelo).replace('.model','.wordvectors')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bClbc9qAhlh9",
        "outputId": "467ce866-7437-4fbe-9dbb-21d7ca19f4cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pasta = r'/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Word Embeddings/Treinamento do nosso modelo/Treinamento com temporalização/SAUDE-CORPO-03-10/Com RE/Treinamento temporal/Modelo 3'\n",
        "\n",
        "caminho_modelos = [os.path.join(pasta,m) for m in os.listdir(pasta) if m.endswith('.model')]\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "pasta_kv = os.path.join(pasta,'WordVectors')\n",
        "if not os.path.exists(pasta_kv):\n",
        "  os.makedirs(pasta_kv)\n",
        "\n",
        "for i,caminho_modelo in enumerate(caminho_modelos):\n",
        "  print(i+1)\n",
        "  word_vectors = Word2Vec.load(caminho_modelo).wv\n",
        "  word_vectors.save(os.path.join(pasta_kv,os.path.basename(caminho_modelo).replace('.model','.wordvectors')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f36CAGdVhpl3",
        "outputId": "d7fc08ea-a816-4f32-e035-7a3ec306911c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Depois de realizado esta operação é necessário compactar num arquivo zip os modelos no formato wordvectors, salvar num local do Drive, deixar seu compartilhamento aberto (qualquer pessoa com link pode ler), copiar o link de compartilhamento e botar o id (que está no meio do link) no programa de Visualizações para que consiga-se baixá-lo e depois descompactá-lo.**\n",
        "\n",
        "A compactação foi pensada também para diminuir o tempo de download dos modelos.\n",
        "\n",
        "Melhores explicações do processo dentro do programa de Visualizações no notebook do mesmo."
      ],
      "metadata": {
        "id": "j6WNjTJ6jJ0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compactar os arquivos dos wordvectors numa pasta \".zip\"\n",
        "\n",
        "**Tentei rodar, mas demora demais, vale mais fazer manualmente pelo Google Drive...**"
      ],
      "metadata": {
        "id": "39fvrVJKVLEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def compactar_pasta(pasta_origem, arquivo_destino):\n",
        "    shutil.make_archive(arquivo_destino, 'zip', pasta_origem)\n",
        "\n",
        "pasta_origem = '/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Word Embeddings/Treinamento do nosso modelo/Treinamento com temporalização/Todas_2003_2006/Com RE/Treinamento incremental/Modelo 4/WordVectors'\n",
        "arquivo_zip = '/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Word Embeddings/Treinamento do nosso modelo/Treinamento com temporalização/Todas_2003_2006/Com RE/Treinamento incremental/Modelo 4/WordVectors/wv4'\n",
        "\n",
        "compactar_pasta(pasta_origem, arquivo_zip)\n",
        "print(f\"Pasta {pasta_origem} compactada para {arquivo_zip}.zip.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "gAv-ei7eOQtq",
        "outputId": "efff32ca-08a7-491a-e99d-098f16741e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "File size unexpectedly exceeded ZIP64 limit",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[1;32m   1775\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1776\u001b[0;31m                 \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mfdst_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compressor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_size\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-04737766d065>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0marquivo_zip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Word Embeddings/Treinamento do nosso modelo/Treinamento com temporalização/Todas_2003_2006/Com RE/Treinamento incremental/Modelo 4/WordVectors/awv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcompactar_pasta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpasta_origem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marquivo_zip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Pasta {pasta_origem} compactada para {arquivo_zip}.zip.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-04737766d065>\u001b[0m in \u001b[0;36mcompactar_pasta\u001b[0;34m(pasta_origem, arquivo_destino)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompactar_pasta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpasta_origem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marquivo_destino\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marquivo_destino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasta_origem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Exemplo de uso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mmake_archive\u001b[0;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msave_cwd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36m_make_zipfile\u001b[0;34m(base_name, base_dir, verbose, dry_run, logger, owner, group, root_dir)\u001b[0m\n\u001b[1;32m   1007\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m                         \u001b[0marcname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marcdirpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m                         \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marcname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adding '%s'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[1;32m   1773\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m                 \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zip64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mZIP64_LIMIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m                         raise RuntimeError(\n\u001b[0m\u001b[1;32m   1171\u001b[0m                             'File size unexpectedly exceeded ZIP64 limit')\n\u001b[1;32m   1172\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mZIP64_LIMIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: File size unexpectedly exceeded ZIP64 limit"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste mudando nome dos arquivos antigos **(em desuso atualmente)**"
      ],
      "metadata": {
        "id": "fyPYocyPb3_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = r'/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Word Embeddings/Treinamento do nosso modelo/Treinamento com temporalização/Todas_2003_2006/Com RE/Treinamento temporal/Modelo 2'\n",
        "\n",
        "lista_arquivos = [os.path.join(c,arq) for arq in os.listdir(c) if '.model' in arq]\n",
        "# print(len(lista_arquivos))\n",
        "# lista_arquivos[0]\n",
        "\n",
        "for caminho_arquivo in lista_arquivos:\n",
        "\n",
        "  nome_arquivo = os.path.basename(caminho_arquivo)\n",
        "  pasta = os.path.dirname(caminho_arquivo)\n",
        "  # print(caminho_arquivo)\n",
        "  # print(pasta)\n",
        "  # print(nome_arquivo)\n",
        "  nome_atualizado = nome_arquivo.replace('_w2v.','_w2v_tmp.')\n",
        "  # print(nome_atualizado)\n",
        "  novo_caminho_arquivo = os.path.join(pasta,nome_atualizado)\n",
        "  print(novo_caminho_arquivo)\n",
        "  os.rename(caminho_arquivo, novo_caminho_arquivo)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JOxzr3Nb7VT",
        "outputId": "cef5803d-0281-4ff5-b0a9-61b1429b1748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Word Embeddings/Treinamento do nosso modelo/Treinamento com temporalização/Todas_2003_2006/Com RE/Treinamento temporal/Modelo 2/WOKE_2_UFSC_2003_2006_w2v_tmp.model.wv.vectors.npy\n",
            "/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Word Embeddings/Treinamento do nosso modelo/Treinamento com temporalização/Todas_2003_2006/Com RE/Treinamento temporal/Modelo 2/WOKE_2_UFSC_2003_2006_w2v_tmp.model.syn1neg.npy\n",
            "/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Word Embeddings/Treinamento do nosso modelo/Treinamento com temporalização/Todas_2003_2006/Com RE/Treinamento temporal/Modelo 2/WOKE_2_UFSC_2003_2006_w2v_tmp.model\n",
            "/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Word Embeddings/Treinamento do nosso modelo/Treinamento com temporalização/Todas_2003_2006/Com RE/Treinamento temporal/Modelo 2/WOKE_2_UFSC_2003_2016_w2v_tmp.model.wv.vectors.npy\n",
            "/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Word Embeddings/Treinamento do nosso modelo/Treinamento com temporalização/Todas_2003_2006/Com RE/Treinamento temporal/Modelo 2/WOKE_2_UFSC_2003_2016_w2v_tmp.model.syn1neg.npy\n",
            "/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Word Embeddings/Treinamento do nosso modelo/Treinamento com temporalização/Todas_2003_2006/Com RE/Treinamento temporal/Modelo 2/WOKE_2_UFSC_2003_2016_w2v_tmp.model\n"
          ]
        }
      ]
    }
  ]
}