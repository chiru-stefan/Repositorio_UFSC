# Informa√ß√£o sobre Modelos WOKE

Para entender melhor como foi feita a coleta da informa√ß√£o de contabiliza√ß√£o dos tokens das diferentes formas, acesse nosso notebook: **[Explicativo - Informa√ß√£o contagens - modelos WOKE](https://colab.research.google.com/drive/1sNh5wCUVKiEt2yD7z8a16D9lr4HytF6b?usp=sharing)**

Al√©m disso, nesta √°rea do GitHub, tamb√©m est√° disponibilizado o notebook que foi utilizado para coleta das informa√ß√µes: *Informacao_Modelos_WOKE.ipynb*.

## ü§ñ WOKE UFSC 2003 - 2006
- Quantidade de m√∫ltiplos treinos para gera√ß√£o de modelo base: **96**

<details>
  <summary><b>Mais informa√ß√µes <i>(clique para expandir)</i></b></summary>
  
  <br>
  <ul><li><b>Quantidade de trabalhos contemplados no total: 30.664</b></li>
  <li><b>Quantidade de cole√ß√µes contempladas: 106</b>
  <br>
    <details>
      <summary>Visualizar cole√ß√µes utilizadas <i>(clique para expandir)</i></summary>
        <ul><li>Administracao</li> <li>Administracao_Universitaria_Mestrado_Profissional</li> <li>Agroecossistemas</li> <li>Agroecossistemas_Mestrado_Profissional</li> <li>Antropologia_Social</li> <li>Aquicultura</li> <li>Arquitetura_e_Urbanismo</li> <li>Assistencia_Farmaceutica</li> <li>Biologia_Celular_e_do_Desenvolvimento</li> <li>Biologia_Vegetal</li> <li>Biologia_de_Fungos_Algas_e_Plantas</li> <li>Bioquimica</li> <li>Biotecnologia</li> <li>Biotecnologia_e_Biociencias</li> <li>Ciencia_da_Computacao</li> <li>Ciencia_da_Informacao</li> <li>Ciencia_dos_Alimentos</li> <li>Ciencia_e_Engenharia_de_Materiais</li> <li>Ciencias_Medicas</li> <li>Ciencias_da_Reabilitacao</li> <li>Contabilidade</li> <li>Controle_de_Gestao_Mestrado_Profissional</li> <li>Cuidados_Intensivos_e_Paliativos_Mestrado_Profissional</li> <li>Desastres_Naturais_Mestrado_Profissional</li> <li>Design</li> <li>Design_e_Expressao_Grafica</li> <li>Direito</li> <li>Direito_Mestrado_Profissional</li> <li>Ecologia</li> <li>Economia</li> <li>Ecossistemas_Agricolas_e_Naturais</li> <li>Educacao</li> <li>Educacao_Cientifica_e_Tecnologica</li> <li>Educacao_Fisica</li> <li>Energia_e_Sustentabilidade</li> <li>Enfermagem</li> <li>Engenharia_Ambiental</li> <li>Engenharia_Ambiental_Mestrado_Profissional</li> <li>Engenharia_Civil</li> <li>Engenharia_Eletrica</li> <li>Engenharia_Mecanica</li> <li>Engenharia_Quimica</li> <li>Engenharia_Textil</li> <li>Engenharia_de_Alimentos</li> <li>Engenharia_de_Automacao_e_Sistemas</li> <li>Engenharia_de_Producao</li> <li>Engenharia_de_Sistemas_Eletronicos</li> <li>Engenharia_de_Transportes_e_Gestao_Territorial</li> <li>Engenharia_e_Ciencias_Mecanicas</li> <li>Engenharia_e_Gestao_do_Conhecimento</li> <li>Ensino_de_Biologia</li> <li>Ensino_de_Biologia_Mestrado_Profissional</li> <li>Ensino_de_Fisica_Mestrado_Profissional</li> <li>Ensino_de_Historia_Mestrado_Profissional</li> <li>Estudos_da_Traducao</li> <li>Farmacia</li> <li>Farmacologia</li> <li>Farmacologia_Mestrado_Profissional</li> <li>Filosofia</li> <li>Fisica</li> <li>Fonoaudiologia</li> <li>Geografia</li> <li>Gestao_do_Cuidado_em_Enfermagem</li> <li>Gestao_do_Cuidado_em_Enfermagem_Mestrado_Profissional</li> <li>Historia</li> <li>Informatica_em_Saude_Mestrado_Profissional</li> <li>Jornalismo</li> <li>Letras_Literatura_Brasileira</li> <li>Letras_Mestrado_Profissional</li> <li>Linguistica</li> <li>Literatura</li> <li>Matematica_Mestrado_Profissional</li> <li>Matematica_Pura_e_Aplicada</li> <li>Matematica_e_Computacao_Cientifica</li> <li>Metodos_e_Gestao_em_Avaliacao_Mestrado_Profissional</li> <li>Metrologia_Cientifica_e_Industrial</li> <li>Neurociencias</li> <li>Nutricao</li> <li>Oceanografia</li> <li>Odontologia</li> <li>Pericias_Criminais_Ambientais_Mestrado_Profissional</li> <li>Programa_de_Pos_Graduacao_Interdisciplinar_em_Ciencias_Humanas</li> <li>Programa_de_Pos_Graduacao_Multicentrico_em_Ciencias_Fisiologicas</li> <li>Programa_de_Pos_Graduacao_Multidisciplinar_em_Saude_Mestrado_Profissional</li> <li>Propriedade_Intelectual_e_Transferencia_de_Tecnologia_para_Inovacao_Mestrado_Profissional</li> <li>Psicologia</li> <li>Quimica</li> <li>Recursos_Geneticos_Vegetais</li> <li>Relacoes_Internacionais</li> <li>Saude_Coletiva</li> <li>Saude_Mental_e_Atencao_Psicossocial_Mestrado_Profissional</li> <li>Saude_Publica</li> <li>Servico_Social</li> <li>Sociologia_Politica</li> <li>Sociologia_e_Ciencia_Politica</li> <li>Tecnologias_da_Informacao_e_Comunicacao</li> <li>Teses_e_dissertacoes_nao_defendidas_na_UFSC</li> <li>Urbanismo_Historia_e_Arquitetura_da_Cidade</li> <li>Engenharia_Mecanica_Mestrado_Profissional</li> <li>Geologia</li> <li>Letras_Ingles_e_Literatura_Correspondente</li> <li>Nanociencia_Processos_e_Materiais_Avancados</li> <li>Medicina_Veterinaria_Convencional_e_Integrativa</li> <li>Ingles_Estudos_Linguisticos_e_Literarios</li> <li>Nanotecnologia_Farmaceutica</li> <li>Teses_e_dissertacoes_do_Centro_Tecnologico</li></ul>
    </details>
  </li></ul>

### Hyperlinks para os temas desta p√°gina

- [Incremental](#incremental)
  - [WOKE UFSC MODELO 1](#woke-ufsc-modelo-1)
  - [WOKE UFSC MODELO 2](#woke-ufsc-modelo-2)
  - [WOKE UFSC MODELO 3](#woke-ufsc-modelo-3)
  - [WOKE UFSC MODELO 4](#woke-ufsc-modelo-4)


- [Temporal](#temporal)
  - [WOKE UFSC MODELO 1](#woke-ufsc-modelo-1-1)
  - [WOKE UFSC MODELO 2](#woke-ufsc-modelo-2-1)
  - [WOKE UFSC MODELO 3](#woke-ufsc-modelo-3-1)
  - [WOKE UFSC MODELO 4](#woke-ufsc-modelo-4-1)


## Incremental
### WOKE UFSC MODELO 1
#### WOKE_1_UFSC_2003_2006_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 5.008
- Quantidade de frases: 6.954.953
- Quantidade de tokens no corpus usado no treino: 103.409.477
- Quantidade de palavras que entraram para o treinamento: 95.961.384
- Quantidade de tokens no vocabul√°rio: 68.574
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2007_2008_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 7.341
- Quantidade de frases: 3.549.449
- Quantidade de tokens no corpus usado no treino: 52.151.874
- Quantidade de palavras que entraram para o treinamento: 144.010.288
- Quantidade de tokens no vocabul√°rio: 73.889
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2009_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 9.710
- Quantidade de frases: 3.589.113
- Quantidade de tokens no corpus usado no treino: 52.301.378
- Quantidade de palavras que entraram para o treinamento: 191.952.178
- Quantidade de tokens no vocabul√°rio: 80.333
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2011_2012_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 12.442
- Quantidade de frases: 4.019.859
- Quantidade de tokens no corpus usado no treino: 58.322.060
- Quantidade de palavras que entraram para o treinamento: 245.451.625
- Quantidade de tokens no vocabul√°rio: 86.666
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2013_2014_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 15.576
- Quantidade de frases: 4.598.336
- Quantidade de tokens no corpus usado no treino: 66.859.472
- Quantidade de palavras que entraram para o treinamento: 306.903.625
- Quantidade de tokens no vocabul√°rio: 94.177
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2015_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 19.063
- Quantidade de frases: 5.413.473
- Quantidade de tokens no corpus usado no treino: 78.640.230
- Quantidade de palavras que entraram para o treinamento: 379.295.588
- Quantidade de tokens no vocabul√°rio: 102.998
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2017_2018_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 22.883
- Quantidade de frases: 5.979.335
- Quantidade de tokens no corpus usado no treino: 86.818.224
- Quantidade de palavras que entraram para o treinamento: 459.368.636
- Quantidade de tokens no vocabul√°rio: 111.849
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2019_2020_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 26.313
- Quantidade de frases: 5.343.904
- Quantidade de tokens no corpus usado no treino: 77.487.203
- Quantidade de palavras que entraram para o treinamento: 530.778.205
- Quantidade de tokens no vocabul√°rio: 118.630
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2021_2022_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 29.436
- Quantidade de frases: 4.971.954
- Quantidade de tokens no corpus usado no treino: 72.756.257
- Quantidade de palavras que entraram para o treinamento: 597.626.882
- Quantidade de tokens no vocabul√°rio: 124.445
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2023_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 30.664
- Quantidade de frases: 1.807.267
- Quantidade de tokens no corpus usado no treino: 26.813.030
- Quantidade de palavras que entraram para o treinamento: 621.966.385
- Quantidade de tokens no vocabul√°rio: 126.252
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

### WOKE UFSC MODELO 2
#### WOKE_2_UFSC_2003_2006_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 5.008
- Quantidade de frases: 6.954.953
- Quantidade de tokens no corpus usado no treino: 103.409.477
- Quantidade de palavras que entraram para o treinamento: 95.349.285
- Quantidade de tokens no vocabul√°rio: 56.669
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2007_2008_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 7.341
- Quantidade de frases: 3.549.449
- Quantidade de tokens no corpus usado no treino: 52.151.874
- Quantidade de palavras que entraram para o treinamento: 143.041.124
- Quantidade de tokens no vocabul√°rio: 60.518
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2009_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 9.710
- Quantidade de frases: 3.589.113
- Quantidade de tokens no corpus usado no treino: 52.301.378
- Quantidade de palavras que entraram para o treinamento: 190.598.557
- Quantidade de tokens no vocabul√°rio: 65.141
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2011_2012_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 12.442
- Quantidade de frases: 4.019.859
- Quantidade de tokens no corpus usado no treino: 58.322.060
- Quantidade de palavras que entraram para o treinamento: 243.676.791
- Quantidade de tokens no vocabul√°rio: 69.862
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2013_2014_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 15.576
- Quantidade de frases: 4.598.336
- Quantidade de tokens no corpus usado no treino: 66.859.472
- Quantidade de palavras que entraram para o treinamento: 304.658.774
- Quantidade de tokens no vocabul√°rio: 75.535
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2015_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 19.063
- Quantidade de frases: 5.413.473
- Quantidade de tokens no corpus usado no treino: 78.640.230
- Quantidade de palavras que entraram para o treinamento: 376.514.234
- Quantidade de tokens no vocabul√°rio: 82.348
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2017_2018_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 22.883
- Quantidade de frases: 5.979.335
- Quantidade de tokens no corpus usado no treino: 86.818.224
- Quantidade de palavras que entraram para o treinamento: 456.014.140
- Quantidade de tokens no vocabul√°rio: 89.051
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2019_2020_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 26.313
- Quantidade de frases: 5.343.904
- Quantidade de tokens no corpus usado no treino: 77.487.203
- Quantidade de palavras que entraram para o treinamento: 526.905.542
- Quantidade de tokens no vocabul√°rio: 94.187
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2021_2022_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 29.436
- Quantidade de frases: 4.971.954
- Quantidade de tokens no corpus usado no treino: 72.756.257
- Quantidade de palavras que entraram para o treinamento: 593.278.313
- Quantidade de tokens no vocabul√°rio: 98.473
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2023_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 30.664
- Quantidade de frases: 1.807.267
- Quantidade de tokens no corpus usado no treino: 26.813.030
- Quantidade de palavras que entraram para o treinamento: 617.437.126
- Quantidade de tokens no vocabul√°rio: 99.731
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

### WOKE UFSC MODELO 3
#### WOKE_3_UFSC_2003_2006_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 5.008
- Quantidade de frases: 6.954.953
- Quantidade de tokens no corpus usado no treino: 103.409.477
- Quantidade de palavras que entraram para o treinamento: 95.961.384
- Quantidade de tokens no vocabul√°rio: 68.574
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2007_2008_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 7.341
- Quantidade de frases: 3.549.449
- Quantidade de tokens no corpus usado no treino: 52.151.874
- Quantidade de palavras que entraram para o treinamento: 144.010.288
- Quantidade de tokens no vocabul√°rio: 73.889
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2009_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 9.710
- Quantidade de frases: 3.589.113
- Quantidade de tokens no corpus usado no treino: 52.301.378
- Quantidade de palavras que entraram para o treinamento: 191.952.178
- Quantidade de tokens no vocabul√°rio: 80.333
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2011_2012_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 12.442
- Quantidade de frases: 4.019.859
- Quantidade de tokens no corpus usado no treino: 58.322.060
- Quantidade de palavras que entraram para o treinamento: 245.451.625
- Quantidade de tokens no vocabul√°rio: 86.666
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2013_2014_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 15.576
- Quantidade de frases: 4.598.336
- Quantidade de tokens no corpus usado no treino: 66.859.472
- Quantidade de palavras que entraram para o treinamento: 157.246.483
- Quantidade de tokens no vocabul√°rio: 80.904
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2015_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 19.063
- Quantidade de frases: 5.413.473
- Quantidade de tokens no corpus usado no treino: 78.640.230
- Quantidade de palavras que entraram para o treinamento: 229.513.880
- Quantidade de tokens no vocabul√°rio: 91.778
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2017_2018_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 22.883
- Quantidade de frases: 5.979.335
- Quantidade de tokens no corpus usado no treino: 86.818.224
- Quantidade de palavras que entraram para o treinamento: 175.724.732
- Quantidade de tokens no vocabul√°rio: 88.224
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2019_2020_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 26.313
- Quantidade de frases: 5.343.904
- Quantidade de tokens no corpus usado no treino: 77.487.203
- Quantidade de palavras que entraram para o treinamento: 246.916.980
- Quantidade de tokens no vocabul√°rio: 97.458
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2021_2022_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 29.436
- Quantidade de frases: 4.971.954
- Quantidade de tokens no corpus usado no treino: 72.756.257
- Quantidade de palavras que entraram para o treinamento: 162.341.885
- Quantidade de tokens no vocabul√°rio: 84.988
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2023_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 30.664
- Quantidade de frases: 1.807.267
- Quantidade de tokens no corpus usado no treino: 26.813.030
- Quantidade de palavras que entraram para o treinamento: 186.499.034
- Quantidade de tokens no vocabul√°rio: 87.504
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

### WOKE UFSC MODELO 4
#### WOKE_4_UFSC_2003_2006_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 5.008
- Quantidade de frases: 6.954.953
- Quantidade de tokens no corpus usado no treino: 103.409.477
- Quantidade de palavras que entraram para o treinamento: 95.349.285
- Quantidade de tokens no vocabul√°rio: 56.669
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2007_2008_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 7.341
- Quantidade de frases: 3.549.449
- Quantidade de tokens no corpus usado no treino: 52.151.874
- Quantidade de palavras que entraram para o treinamento: 143.041.124
- Quantidade de tokens no vocabul√°rio: 60.518
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2009_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 9.710
- Quantidade de frases: 3.589.113
- Quantidade de tokens no corpus usado no treino: 52.301.378
- Quantidade de palavras que entraram para o treinamento: 190.598.557
- Quantidade de tokens no vocabul√°rio: 65.141
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2011_2012_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 12.442
- Quantidade de frases: 4.019.859
- Quantidade de tokens no corpus usado no treino: 58.322.060
- Quantidade de palavras que entraram para o treinamento: 243.676.791
- Quantidade de tokens no vocabul√°rio: 69.862
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2013_2014_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 15.576
- Quantidade de frases: 4.598.336
- Quantidade de tokens no corpus usado no treino: 66.859.472
- Quantidade de palavras que entraram para o treinamento: 304.658.774
- Quantidade de tokens no vocabul√°rio: 75.535
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2015_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 19.063
- Quantidade de frases: 5.413.473
- Quantidade de tokens no corpus usado no treino: 78.640.230
- Quantidade de palavras que entraram para o treinamento: 166.975.166
- Quantidade de tokens no vocabul√°rio: 69.659
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2017_2018_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 22.883
- Quantidade de frases: 5.979.335
- Quantidade de tokens no corpus usado no treino: 86.818.224
- Quantidade de palavras que entraram para o treinamento: 246.311.336
- Quantidade de tokens no vocabul√°rio: 78.262
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2019_2020_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 26.313
- Quantidade de frases: 5.343.904
- Quantidade de tokens no corpus usado no treino: 77.487.203
- Quantidade de palavras que entraram para o treinamento: 165.801.271
- Quantidade de tokens no vocabul√°rio: 70.499
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2021_2022_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 29.436
- Quantidade de frases: 4.971.954
- Quantidade de tokens no corpus usado no treino: 72.756.257
- Quantidade de palavras que entraram para o treinamento: 231.860.234
- Quantidade de tokens no vocabul√°rio: 77.136
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2023_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 30.664
- Quantidade de frases: 1.807.267
- Quantidade de tokens no corpus usado no treino: 26.813.030
- Quantidade de palavras que entraram para o treinamento: 255.900.500
- Quantidade de tokens no vocabul√°rio: 78.645
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---


## Temporal
### WOKE UFSC MODELO 1
#### WOKE_1_UFSC_2003_2006_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 5.008
- Quantidade de frases: 6.954.953
- Quantidade de tokens no corpus usado no treino: 103.409.477
- Quantidade de palavras que entraram para o treinamento: 95.961.384
- Quantidade de tokens no vocabul√°rio: 68.574
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2003_2008_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 7.341
- Quantidade de frases: 10.504.402
- Quantidade de tokens no corpus usado no treino: 155.561.351
- Quantidade de palavras que entraram para o treinamento: 145.089.242
- Quantidade de tokens no vocabul√°rio: 91.577
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 9.710
- Quantidade de frases: 14.093.515
- Quantidade de tokens no corpus usado no treino: 207.862.729
- Quantidade de palavras que entraram para o treinamento: 194.339.554
- Quantidade de tokens no vocabul√°rio: 113.866
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2003_2012_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 12.442
- Quantidade de frases: 18.113.374
- Quantidade de tokens no corpus usado no treino: 266.184.789
- Quantidade de palavras que entraram para o treinamento: 249.361.114
- Quantidade de tokens no vocabul√°rio: 135.690
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2003_2014_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 15.576
- Quantidade de frases: 22.711.710
- Quantidade de tokens no corpus usado no treino: 333.044.261
- Quantidade de palavras que entraram para o treinamento: 312.582.656
- Quantidade de tokens no vocabul√°rio: 158.822
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 19.063
- Quantidade de frases: 28.125.183
- Quantidade de tokens no corpus usado no treino: 411.684.491
- Quantidade de palavras que entraram para o treinamento: 387.107.285
- Quantidade de tokens no vocabul√°rio: 184.847
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2003_2018_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 22.883
- Quantidade de frases: 34.104.518
- Quantidade de tokens no corpus usado no treino: 498.502.715
- Quantidade de palavras que entraram para o treinamento: 469.458.520
- Quantidade de tokens no vocabul√°rio: 211.144
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2003_2020_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 26.313
- Quantidade de frases: 39.448.422
- Quantidade de tokens no corpus usado no treino: 575.989.918
- Quantidade de palavras que entraram para o treinamento: 542.979.577
- Quantidade de tokens no vocabul√°rio: 233.995
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2003_2022_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 29.436
- Quantidade de frases: 44.420.376
- Quantidade de tokens no corpus usado no treino: 648.746.175
- Quantidade de palavras que entraram para o treinamento: 611.803.023
- Quantidade de tokens no vocabul√°rio: 254.264
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_UFSC_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 30.664
- Quantidade de frases: 46.227.643
- Quantidade de tokens no corpus usado no treino: 675.559.205
- Quantidade de palavras que entraram para o treinamento: 636.930.327
- Quantidade de tokens no vocabul√°rio: 262.207
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

### WOKE UFSC MODELO 2
#### WOKE_2_UFSC_2003_2006_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 5.008
- Quantidade de frases: 6.954.953
- Quantidade de tokens no corpus usado no treino: 103.409.477
- Quantidade de palavras que entraram para o treinamento: 95.349.285
- Quantidade de tokens no vocabul√°rio: 56.669
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2003_2008_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 7.341
- Quantidade de frases: 10.504.402
- Quantidade de tokens no corpus usado no treino: 155.561.351
- Quantidade de palavras que entraram para o treinamento: 144.273.606
- Quantidade de tokens no vocabul√°rio: 75.709
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 9.710
- Quantidade de frases: 14.093.515
- Quantidade de tokens no corpus usado no treino: 207.862.729
- Quantidade de palavras que entraram para o treinamento: 193.315.891
- Quantidade de tokens no vocabul√°rio: 93.940
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2003_2012_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 12.442
- Quantidade de frases: 18.113.374
- Quantidade de tokens no corpus usado no treino: 266.184.789
- Quantidade de palavras que entraram para o treinamento: 248.119.080
- Quantidade de tokens no vocabul√°rio: 111.533
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2003_2014_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 15.576
- Quantidade de frases: 22.711.710
- Quantidade de tokens no corpus usado no treino: 333.044.261
- Quantidade de palavras que entraram para o treinamento: 311.142.132
- Quantidade de tokens no vocabul√°rio: 130.795
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 19.063
- Quantidade de frases: 28.125.183
- Quantidade de tokens no corpus usado no treino: 411.684.491
- Quantidade de palavras que entraram para o treinamento: 385.398.030
- Quantidade de tokens no vocabul√°rio: 151.603
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2003_2018_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 22.883
- Quantidade de frases: 34.104.518
- Quantidade de tokens no corpus usado no treino: 498.502.715
- Quantidade de palavras que entraram para o treinamento: 467.498.259
- Quantidade de tokens no vocabul√°rio: 173.001
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2003_2020_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 26.313
- Quantidade de frases: 39.448.422
- Quantidade de tokens no corpus usado no treino: 575.989.918
- Quantidade de palavras que entraram para o treinamento: 540.807.246
- Quantidade de tokens no vocabul√°rio: 191.718
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2003_2022_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 29.436
- Quantidade de frases: 44.420.376
- Quantidade de tokens no corpus usado no treino: 648.746.175
- Quantidade de palavras que entraram para o treinamento: 609.438.264
- Quantidade de tokens no vocabul√°rio: 208.233
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_UFSC_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 30.664
- Quantidade de frases: 46.227.643
- Quantidade de tokens no corpus usado no treino: 675.559.205
- Quantidade de palavras que entraram para o treinamento: 634.486.228
- Quantidade de tokens no vocabul√°rio: 214.627
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

### WOKE UFSC MODELO 3
#### WOKE_3_UFSC_2003_2006_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 5.008
- Quantidade de frases: 6.954.953
- Quantidade de tokens no corpus usado no treino: 103.409.477
- Quantidade de palavras que entraram para o treinamento: 95.961.384
- Quantidade de tokens no vocabul√°rio: 68.574
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2003_2008_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 7.341
- Quantidade de frases: 10.504.402
- Quantidade de tokens no corpus usado no treino: 155.561.351
- Quantidade de palavras que entraram para o treinamento: 145.089.242
- Quantidade de tokens no vocabul√°rio: 91.577
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 9.710
- Quantidade de frases: 14.093.515
- Quantidade de tokens no corpus usado no treino: 207.862.729
- Quantidade de palavras que entraram para o treinamento: 194.339.554
- Quantidade de tokens no vocabul√°rio: 113.866
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2003_2012_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 12.442
- Quantidade de frases: 18.113.374
- Quantidade de tokens no corpus usado no treino: 266.184.789
- Quantidade de palavras que entraram para o treinamento: 249.361.114
- Quantidade de tokens no vocabul√°rio: 135.690
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2003_2014_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 15.576
- Quantidade de frases: 22.711.710
- Quantidade de tokens no corpus usado no treino: 333.044.261
- Quantidade de palavras que entraram para o treinamento: 312.582.656
- Quantidade de tokens no vocabul√°rio: 158.822
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 19.063
- Quantidade de frases: 28.125.183
- Quantidade de tokens no corpus usado no treino: 411.684.491
- Quantidade de palavras que entraram para o treinamento: 387.107.285
- Quantidade de tokens no vocabul√°rio: 184.847
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2003_2018_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 22.883
- Quantidade de frases: 34.104.518
- Quantidade de tokens no corpus usado no treino: 498.502.715
- Quantidade de palavras que entraram para o treinamento: 469.458.520
- Quantidade de tokens no vocabul√°rio: 211.144
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2003_2020_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 26.313
- Quantidade de frases: 39.448.422
- Quantidade de tokens no corpus usado no treino: 575.989.918
- Quantidade de palavras que entraram para o treinamento: 542.979.577
- Quantidade de tokens no vocabul√°rio: 233.995
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2003_2022_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 29.436
- Quantidade de frases: 44.420.376
- Quantidade de tokens no corpus usado no treino: 648.746.175
- Quantidade de palavras que entraram para o treinamento: 611.803.023
- Quantidade de tokens no vocabul√°rio: 254.264
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_UFSC_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 30.664
- Quantidade de frases: 46.227.643
- Quantidade de tokens no corpus usado no treino: 675.559.205
- Quantidade de palavras que entraram para o treinamento: 636.930.327
- Quantidade de tokens no vocabul√°rio: 262.207
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

### WOKE UFSC MODELO 4
#### WOKE_4_UFSC_2003_2006_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 5.008
- Quantidade de frases: 6.954.953
- Quantidade de tokens no corpus usado no treino: 103.409.477
- Quantidade de palavras que entraram para o treinamento: 95.349.285
- Quantidade de tokens no vocabul√°rio: 56.669
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2003_2008_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 7.341
- Quantidade de frases: 10.504.402
- Quantidade de tokens no corpus usado no treino: 155.561.351
- Quantidade de palavras que entraram para o treinamento: 144.273.606
- Quantidade de tokens no vocabul√°rio: 75.709
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 9.710
- Quantidade de frases: 14.093.515
- Quantidade de tokens no corpus usado no treino: 207.862.729
- Quantidade de palavras que entraram para o treinamento: 193.315.891
- Quantidade de tokens no vocabul√°rio: 93.940
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2003_2012_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 12.442
- Quantidade de frases: 18.113.374
- Quantidade de tokens no corpus usado no treino: 266.184.789
- Quantidade de palavras que entraram para o treinamento: 248.119.080
- Quantidade de tokens no vocabul√°rio: 111.533
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2003_2014_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 15.576
- Quantidade de frases: 22.711.710
- Quantidade de tokens no corpus usado no treino: 333.044.261
- Quantidade de palavras que entraram para o treinamento: 311.142.132
- Quantidade de tokens no vocabul√°rio: 130.795
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 19.063
- Quantidade de frases: 28.125.183
- Quantidade de tokens no corpus usado no treino: 411.684.491
- Quantidade de palavras que entraram para o treinamento: 385.398.030
- Quantidade de tokens no vocabul√°rio: 151.603
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2003_2018_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 22.883
- Quantidade de frases: 34.104.518
- Quantidade de tokens no corpus usado no treino: 498.502.715
- Quantidade de palavras que entraram para o treinamento: 467.498.259
- Quantidade de tokens no vocabul√°rio: 173.001
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2003_2020_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 26.313
- Quantidade de frases: 39.448.422
- Quantidade de tokens no corpus usado no treino: 575.989.918
- Quantidade de palavras que entraram para o treinamento: 540.807.246
- Quantidade de tokens no vocabul√°rio: 191.718
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2003_2022_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 29.436
- Quantidade de frases: 44.420.376
- Quantidade de tokens no corpus usado no treino: 648.746.175
- Quantidade de palavras que entraram para o treinamento: 609.438.264
- Quantidade de tokens no vocabul√°rio: 208.233
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_4_UFSC_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 30.664
- Quantidade de frases: 46.227.643
- Quantidade de tokens no corpus usado no treino: 675.559.205
- Quantidade de palavras que entraram para o treinamento: 634.486.228
- Quantidade de tokens no vocabul√°rio: 214.627
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 500
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---


</details>


## ü§ñ WOKE CFH-03-10
- Quantidade de m√∫ltiplos treinos para gera√ß√£o de modelo base: **584**
<details>
  <summary><b>Mais informa√ß√µes <i>(clique para expandir)</i></b></summary>
  <br>
  <ul><li><b>Quantidade de trabalhos contemplados no total: 3.554</b></li>
  <li><b>Quantidade de cole√ß√µes contempladas: 12</b>
  <br>
    <details>
      <summary>Visualizar cole√ß√µes utilizadas <i>(clique para expandir)</i></summary>
        <ul><li>Filosofia</li> <li>Geografia</li> <li>Geologia</li> <li>Historia</li> <li>Psicologia</li> <li>Teses_e_dissertacoes_do_Centro_de_Filosofia_e_Ciencias_Humanas</li> <li>Programa_de_Pos_Graduacao_Interdisciplinar_em_Ciencias_Humanas</li> <li>Servico_Social</li> <li>Sociologia_e_Ciencia_Politica</li> <li>Sociologia_Politica</li> <li>Saude_Mental_e_Atencao_Psicossocial_Mestrado_Profissional</li> <li>Ensino_de_Historia_Mestrado_Profissional</li></ul>
    </details></li></ul>

### Hyperlinks para os temas desta p√°gina

- [Incremental](#incremental)
  - [WOKE CFH MODELO 1](#woke-cfh-modelo-1)
  - [WOKE CFH MODELO 2](#woke-cfh-modelo-2)
  - [WOKE CFH MODELO 3](#woke-cfh-modelo-3)


- [Temporal](#temporal)
  - [WOKE CFH MODELO 1](#woke-cfh-modelo-1-1)
  - [WOKE CFH MODELO 2](#woke-cfh-modelo-2-1)
  - [WOKE CFH MODELO 3](#woke-cfh-modelo-3-1)


## Incremental
### WOKE CFH MODELO 1
#### WOKE_1_CFH_2003_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.074
- Quantidade de frases: 2.354.048
- Quantidade de tokens no corpus usado no treino: 34.137.504
- Quantidade de palavras que entraram para o treinamento: 31.962.981
- Quantidade de tokens no vocabul√°rio: 41.628
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_1_CFH_2011_2013_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.608
- Quantidade de frases: 1.191.385
- Quantidade de tokens no corpus usado no treino: 17.669.890
- Quantidade de palavras que entraram para o treinamento: 48.473.069
- Quantidade de tokens no vocabul√°rio: 44.563
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_1_CFH_2014_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 2.217
- Quantidade de frases: 1.399.659
- Quantidade de tokens no corpus usado no treino: 20.441.299
- Quantidade de palavras que entraram para o treinamento: 67.510.694
- Quantidade de tokens no vocabul√°rio: 48.331
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_1_CFH_2017_2019_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 2.888
- Quantidade de frases: 1.538.214
- Quantidade de tokens no corpus usado no treino: 22.951.565
- Quantidade de palavras que entraram para o treinamento: 88.948.727
- Quantidade de tokens no vocabul√°rio: 52.545
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_1_CFH_2020_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 3.554
- Quantidade de frases: 1.502.951
- Quantidade de tokens no corpus usado no treino: 22.512.208
- Quantidade de palavras que entraram para o treinamento: 109.806.862
- Quantidade de tokens no vocabul√°rio: 57.032
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

### WOKE CFH MODELO 2
#### WOKE_2_CFH_2003_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.074
- Quantidade de frases: 2.354.048
- Quantidade de tokens no corpus usado no treino: 34.137.504
- Quantidade de palavras que entraram para o treinamento: 31.631.016
- Quantidade de tokens no vocabul√°rio: 32.441
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_2_CFH_2011_2013_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.608
- Quantidade de frases: 1.191.385
- Quantidade de tokens no corpus usado no treino: 17.669.890
- Quantidade de palavras que entraram para o treinamento: 47.968.421
- Quantidade de tokens no vocabul√°rio: 34.396
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_2_CFH_2014_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 2.217
- Quantidade de frases: 1.399.659
- Quantidade de tokens no corpus usado no treino: 20.441.299
- Quantidade de palavras que entraram para o treinamento: 66.796.682
- Quantidade de tokens no vocabul√°rio: 36.894
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_2_CFH_2017_2019_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 2.888
- Quantidade de frases: 1.538.214
- Quantidade de tokens no corpus usado no treino: 22.951.565
- Quantidade de palavras que entraram para o treinamento: 88.003.531
- Quantidade de tokens no vocabul√°rio: 39.709
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_2_CFH_2020_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 3.554
- Quantidade de frases: 1.502.951
- Quantidade de tokens no corpus usado no treino: 22.512.208
- Quantidade de palavras que entraram para o treinamento: 108.622.050
- Quantidade de tokens no vocabul√°rio: 42.681
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

### WOKE CFH MODELO 3
#### WOKE_3_CFH_2003_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.074
- Quantidade de frases: 2.354.048
- Quantidade de tokens no corpus usado no treino: 34.137.504
- Quantidade de palavras que entraram para o treinamento: 32.249.400
- Quantidade de tokens no vocabul√°rio: 53.592
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---

#### WOKE_3_CFH_2011_2013_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.608
- Quantidade de frases: 1.191.385
- Quantidade de tokens no corpus usado no treino: 17.669.890
- Quantidade de palavras que entraram para o treinamento: 48.908.235
- Quantidade de tokens no vocabul√°rio: 58.091
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---

#### WOKE_3_CFH_2014_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 2.217
- Quantidade de frases: 1.399.659
- Quantidade de tokens no corpus usado no treino: 20.441.299
- Quantidade de palavras que entraram para o treinamento: 68.131.281
- Quantidade de tokens no vocabul√°rio: 63.899
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---

#### WOKE_3_CFH_2017_2019_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 2.888
- Quantidade de frases: 1.538.214
- Quantidade de tokens no corpus usado no treino: 22.951.565
- Quantidade de palavras que entraram para o treinamento: 89.770.760
- Quantidade de tokens no vocabul√°rio: 70.237
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---

#### WOKE_3_CFH_2020_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 3.554
- Quantidade de frases: 1.502.951
- Quantidade de tokens no corpus usado no treino: 22.512.208
- Quantidade de palavras que entraram para o treinamento: 110.836.691
- Quantidade de tokens no vocabul√°rio: 76.964
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---


## Temporal
### WOKE CFH MODELO 1
#### WOKE_1_CFH_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.074
- Quantidade de frases: 2.354.048
- Quantidade de tokens no corpus usado no treino: 34.137.504
- Quantidade de palavras que entraram para o treinamento: 31.962.981
- Quantidade de tokens no vocabul√°rio: 41.628
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_1_CFH_2003_2013_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.608
- Quantidade de frases: 3.545.433
- Quantidade de tokens no corpus usado no treino: 51.807.394
- Quantidade de palavras que entraram para o treinamento: 48.830.872
- Quantidade de tokens no vocabul√°rio: 53.418
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_1_CFH_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 2.217
- Quantidade de frases: 4.945.092
- Quantidade de tokens no corpus usado no treino: 72.248.693
- Quantidade de palavras que entraram para o treinamento: 68.351.277
- Quantidade de tokens no vocabul√°rio: 65.992
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_1_CFH_2003_2019_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 2.888
- Quantidade de frases: 6.483.306
- Quantidade de tokens no corpus usado no treino: 95.200.258
- Quantidade de palavras que entraram para o treinamento: 90.343.370
- Quantidade de tokens no vocabul√°rio: 78.479
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_1_CFH_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 3.554
- Quantidade de frases: 7.986.257
- Quantidade de tokens no corpus usado no treino: 117.712.466
- Quantidade de palavras que entraram para o treinamento: 111.787.322
- Quantidade de tokens no vocabul√°rio: 90.891
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

### WOKE CFH MODELO 2
#### WOKE_2_CFH_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.074
- Quantidade de frases: 2.354.048
- Quantidade de tokens no corpus usado no treino: 34.137.504
- Quantidade de palavras que entraram para o treinamento: 31.631.016
- Quantidade de tokens no vocabul√°rio: 32.441
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_2_CFH_2003_2013_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.608
- Quantidade de frases: 3.545.433
- Quantidade de tokens no corpus usado no treino: 51.807.394
- Quantidade de palavras que entraram para o treinamento: 48.404.895
- Quantidade de tokens no vocabul√°rio: 41.650
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_2_CFH_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 2.217
- Quantidade de frases: 4.945.092
- Quantidade de tokens no corpus usado no treino: 72.248.693
- Quantidade de palavras que entraram para o treinamento: 67.823.884
- Quantidade de tokens no vocabul√°rio: 51.415
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_2_CFH_2003_2019_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 2.888
- Quantidade de frases: 6.483.306
- Quantidade de tokens no corpus usado no treino: 95.200.258
- Quantidade de palavras que entraram para o treinamento: 89.708.563
- Quantidade de tokens no vocabul√°rio: 60.901
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_2_CFH_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 3.554
- Quantidade de frases: 7.986.257
- Quantidade de tokens no corpus usado no treino: 117.712.466
- Quantidade de palavras que entraram para o treinamento: 111.037.755
- Quantidade de tokens no vocabul√°rio: 70.118
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

### WOKE CFH MODELO 3
#### WOKE_3_CFH_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.074
- Quantidade de frases: 2.354.048
- Quantidade de tokens no corpus usado no treino: 34.137.504
- Quantidade de palavras que entraram para o treinamento: 32.249.400
- Quantidade de tokens no vocabul√°rio: 53.592
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---

#### WOKE_3_CFH_2003_2013_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.608
- Quantidade de frases: 3.545.433
- Quantidade de tokens no corpus usado no treino: 51.807.394
- Quantidade de palavras que entraram para o treinamento: 49.204.283
- Quantidade de tokens no vocabul√°rio: 69.026
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---

#### WOKE_3_CFH_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 2.217
- Quantidade de frases: 4.945.092
- Quantidade de tokens no corpus usado no treino: 72.248.693
- Quantidade de palavras que entraram para o treinamento: 68.823.075
- Quantidade de tokens no vocabul√°rio: 85.736
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---

#### WOKE_3_CFH_2003_2019_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 2.888
- Quantidade de frases: 6.483.306
- Quantidade de tokens no corpus usado no treino: 95.200.258
- Quantidade de palavras que entraram para o treinamento: 90.917.767
- Quantidade de tokens no vocabul√°rio: 102.478
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---

#### WOKE_3_CFH_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 3.554
- Quantidade de frases: 7.986.257
- Quantidade de tokens no corpus usado no treino: 117.712.466
- Quantidade de palavras que entraram para o treinamento: 112.464.060
- Quantidade de tokens no vocabul√°rio: 119.178
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---


</details>

## ü§ñ WOKE HST-03-10
- Quantidade de m√∫ltiplos treinos para gera√ß√£o de modelo base: **504**

<details>
  <summary><b>Mais informa√ß√µes <i>(clique para expandir)</i></b></summary>
  <br>
  <ul><li><b>Quantidade de trabalhos contemplados no total: 555</b></li>
  <li><b>Quantidade de cole√ß√µes contempladas: 1</b>
  <br>
    <details>
      <summary>Visualizar cole√ß√µes utilizadas <i>(clique para expandir)</i></summary>
        <ul><li>Historia</li></ul>
    </details>
  </li></ul>

### Hyperlinks para os temas desta p√°gina

- [Incremental](#incremental)
  - [WOKE HST MODELO 1](#woke-hst-modelo-1)
  - [WOKE HST MODELO 2](#woke-hst-modelo-2)
  - [WOKE HST MODELO 3](#woke-hst-modelo-3)
  - [WOKE HST MODELO 4](#woke-hst-modelo-4)


- [Temporal](#temporal)
  - [WOKE HST MODELO 1](#woke-hst-modelo-1-1)
  - [WOKE HST MODELO 2](#woke-hst-modelo-2-1)
  - [WOKE HST MODELO 3](#woke-hst-modelo-3-1)
  - [WOKE HST MODELO 4](#woke-hst-modelo-4-1)
 

## Incremental
### WOKE HST MODELO 1
#### WOKE_1_HST_2003_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 167
- Quantidade de frases: 442.636
- Quantidade de tokens no corpus usado no treino: 5.548.793
- Quantidade de palavras que entraram para o treinamento: 4.760.532
- Quantidade de tokens no vocabul√°rio: 11.465
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_HST_2011_2013_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 249
- Quantidade de frases: 243.348
- Quantidade de tokens no corpus usado no treino: 3.100.347
- Quantidade de palavras que entraram para o treinamento: 7.386.474
- Quantidade de tokens no vocabul√°rio: 12.206
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_HST_2014_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 344
- Quantidade de frases: 305.802
- Quantidade de tokens no corpus usado no treino: 4.011.264
- Quantidade de palavras que entraram para o treinamento: 10.835.615
- Quantidade de tokens no vocabul√°rio: 13.278
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_HST_2017_2019_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 445
- Quantidade de frases: 336.958
- Quantidade de tokens no corpus usado no treino: 4.551.670
- Quantidade de palavras que entraram para o treinamento: 14.722.910
- Quantidade de tokens no vocabul√°rio: 14.539
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_HST_2020_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 555
- Quantidade de frases: 355.330
- Quantidade de tokens no corpus usado no treino: 4.895.643
- Quantidade de palavras que entraram para o treinamento: 18.890.441
- Quantidade de tokens no vocabul√°rio: 16.020
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

### WOKE HST MODELO 2
#### WOKE_2_HST_2003_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 167
- Quantidade de frases: 442.636
- Quantidade de tokens no corpus usado no treino: 5.548.793
- Quantidade de palavras que entraram para o treinamento: 4.660.133
- Quantidade de tokens no vocabul√°rio: 9.514
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_HST_2011_2013_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 249
- Quantidade de frases: 243.348
- Quantidade de tokens no corpus usado no treino: 3.100.347
- Quantidade de palavras que entraram para o treinamento: 7.224.898
- Quantidade de tokens no vocabul√°rio: 10.064
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_HST_2014_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 344
- Quantidade de frases: 305.802
- Quantidade de tokens no corpus usado no treino: 4.011.264
- Quantidade de palavras que entraram para o treinamento: 10.598.618
- Quantidade de tokens no vocabul√°rio: 10.829
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_HST_2017_2019_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 445
- Quantidade de frases: 336.958
- Quantidade de tokens no corpus usado no treino: 4.551.670
- Quantidade de palavras que entraram para o treinamento: 14.402.473
- Quantidade de tokens no vocabul√°rio: 11.801
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_HST_2020_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 555
- Quantidade de frases: 355.330
- Quantidade de tokens no corpus usado no treino: 4.895.643
- Quantidade de palavras que entraram para o treinamento: 18.481.091
- Quantidade de tokens no vocabul√°rio: 12.962
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

### WOKE HST MODELO 3
#### WOKE_3_HST_2003_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 167
- Quantidade de frases: 442.636
- Quantidade de tokens no corpus usado no treino: 5.548.793
- Quantidade de palavras que entraram para o treinamento: 4.760.532
- Quantidade de tokens no vocabul√°rio: 11.465
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 5
- window: 8
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_HST_2011_2013_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 249
- Quantidade de frases: 243.348
- Quantidade de tokens no corpus usado no treino: 3.100.347
- Quantidade de palavras que entraram para o treinamento: 7.386.474
- Quantidade de tokens no vocabul√°rio: 12.206
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 5
- window: 8
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_HST_2014_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 344
- Quantidade de frases: 305.802
- Quantidade de tokens no corpus usado no treino: 4.011.264
- Quantidade de palavras que entraram para o treinamento: 10.835.615
- Quantidade de tokens no vocabul√°rio: 13.278
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 5
- window: 8
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_HST_2017_2019_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 445
- Quantidade de frases: 336.958
- Quantidade de tokens no corpus usado no treino: 4.551.670
- Quantidade de palavras que entraram para o treinamento: 14.722.910
- Quantidade de tokens no vocabul√°rio: 14.539
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 5
- window: 8
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_HST_2020_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 555
- Quantidade de frases: 355.330
- Quantidade de tokens no corpus usado no treino: 4.895.643
- Quantidade de palavras que entraram para o treinamento: 18.890.441
- Quantidade de tokens no vocabul√°rio: 16.020
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 5
- window: 8
- epochs 5
- alpha 0.025
- min_count: 45


---

### WOKE HST MODELO 4
#### WOKE_4_HST_2003_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 167
- Quantidade de frases: 442.636
- Quantidade de tokens no corpus usado no treino: 5.548.793
- Quantidade de palavras que entraram para o treinamento: 4.883.691
- Quantidade de tokens no vocabul√°rio: 14.878
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_4_HST_2011_2013_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 249
- Quantidade de frases: 243.348
- Quantidade de tokens no corpus usado no treino: 3.100.347
- Quantidade de palavras que entraram para o treinamento: 7.583.838
- Quantidade de tokens no vocabul√°rio: 16.027
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_4_HST_2014_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 344
- Quantidade de frases: 305.802
- Quantidade de tokens no corpus usado no treino: 4.011.264
- Quantidade de palavras que entraram para o treinamento: 11.124.215
- Quantidade de tokens no vocabul√°rio: 17.670
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_4_HST_2017_2019_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 445
- Quantidade de frases: 336.958
- Quantidade de tokens no corpus usado no treino: 4.551.670
- Quantidade de palavras que entraram para o treinamento: 15.113.971
- Quantidade de tokens no vocabul√°rio: 19.486
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_4_HST_2020_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 555
- Quantidade de frases: 355.330
- Quantidade de tokens no corpus usado no treino: 4.895.643
- Quantidade de palavras que entraram para o treinamento: 19.389.677
- Quantidade de tokens no vocabul√°rio: 21.650
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---


## Temporal
### WOKE HST MODELO 1
#### WOKE_1_HST_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 167
- Quantidade de frases: 442.636
- Quantidade de tokens no corpus usado no treino: 5.548.793
- Quantidade de palavras que entraram para o treinamento: 4.760.532
- Quantidade de tokens no vocabul√°rio: 11.465
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_HST_2003_2013_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 249
- Quantidade de frases: 685.984
- Quantidade de tokens no corpus usado no treino: 8.649.140
- Quantidade de palavras que entraram para o treinamento: 7.576.514
- Quantidade de tokens no vocabul√°rio: 15.352
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_HST_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 344
- Quantidade de frases: 991.786
- Quantidade de tokens no corpus usado no treino: 12.660.404
- Quantidade de palavras que entraram para o treinamento: 11.275.737
- Quantidade de tokens no vocabul√°rio: 19.327
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_HST_2003_2019_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 445
- Quantidade de frases: 1.328.744
- Quantidade de tokens no corpus usado no treino: 17.212.074
- Quantidade de palavras que entraram para o treinamento: 15.466.865
- Quantidade de tokens no vocabul√°rio: 23.511
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_1_HST_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 555
- Quantidade de frases: 1.684.074
- Quantidade de tokens no corpus usado no treino: 22.107.717
- Quantidade de palavras que entraram para o treinamento: 19.957.792
- Quantidade de tokens no vocabul√°rio: 27.647
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

### WOKE HST MODELO 2
#### WOKE_2_HST_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 167
- Quantidade de frases: 442.636
- Quantidade de tokens no corpus usado no treino: 5.548.793
- Quantidade de palavras que entraram para o treinamento: 4.660.133
- Quantidade de tokens no vocabul√°rio: 9.514
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_HST_2003_2013_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 249
- Quantidade de frases: 685.984
- Quantidade de tokens no corpus usado no treino: 8.649.140
- Quantidade de palavras que entraram para o treinamento: 7.445.282
- Quantidade de tokens no vocabul√°rio: 12.802
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_HST_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 344
- Quantidade de frases: 991.786
- Quantidade de tokens no corpus usado no treino: 12.660.404
- Quantidade de palavras que entraram para o treinamento: 11.114.269
- Quantidade de tokens no vocabul√°rio: 16.193
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_HST_2003_2019_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 445
- Quantidade de frases: 1.328.744
- Quantidade de tokens no corpus usado no treino: 17.212.074
- Quantidade de palavras que entraram para o treinamento: 15.266.693
- Quantidade de tokens no vocabul√°rio: 19.612
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

#### WOKE_2_HST_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 555
- Quantidade de frases: 1.684.074
- Quantidade de tokens no corpus usado no treino: 22.107.717
- Quantidade de palavras que entraram para o treinamento: 19.721.859
- Quantidade de tokens no vocabul√°rio: 23.050
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 60


---

### WOKE HST MODELO 3
#### WOKE_3_HST_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 167
- Quantidade de frases: 442.636
- Quantidade de tokens no corpus usado no treino: 5.548.793
- Quantidade de palavras que entraram para o treinamento: 4.760.532
- Quantidade de tokens no vocabul√°rio: 11.465
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 5
- window: 8
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_HST_2003_2013_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 249
- Quantidade de frases: 685.984
- Quantidade de tokens no corpus usado no treino: 8.649.140
- Quantidade de palavras que entraram para o treinamento: 7.576.514
- Quantidade de tokens no vocabul√°rio: 15.352
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 5
- window: 8
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_HST_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 344
- Quantidade de frases: 991.786
- Quantidade de tokens no corpus usado no treino: 12.660.404
- Quantidade de palavras que entraram para o treinamento: 11.275.737
- Quantidade de tokens no vocabul√°rio: 19.327
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 5
- window: 8
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_HST_2003_2019_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 445
- Quantidade de frases: 1.328.744
- Quantidade de tokens no corpus usado no treino: 17.212.074
- Quantidade de palavras que entraram para o treinamento: 15.466.865
- Quantidade de tokens no vocabul√°rio: 23.511
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 5
- window: 8
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_3_HST_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 555
- Quantidade de frases: 1.684.074
- Quantidade de tokens no corpus usado no treino: 22.107.717
- Quantidade de palavras que entraram para o treinamento: 19.957.792
- Quantidade de tokens no vocabul√°rio: 27.647
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 5
- window: 8
- epochs 5
- alpha 0.025
- min_count: 45


---

### WOKE HST MODELO 4
#### WOKE_4_HST_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 167
- Quantidade de frases: 442.636
- Quantidade de tokens no corpus usado no treino: 5.548.793
- Quantidade de palavras que entraram para o treinamento: 4.883.691
- Quantidade de tokens no vocabul√°rio: 14.878
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_4_HST_2003_2013_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 249
- Quantidade de frases: 685.984
- Quantidade de tokens no corpus usado no treino: 8.649.140
- Quantidade de palavras que entraram para o treinamento: 7.737.992
- Quantidade de tokens no vocabul√°rio: 19.799
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_4_HST_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 344
- Quantidade de frases: 991.786
- Quantidade de tokens no corpus usado no treino: 12.660.404
- Quantidade de palavras que entraram para o treinamento: 11.482.174
- Quantidade de tokens no vocabul√°rio: 25.029
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_4_HST_2003_2019_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 445
- Quantidade de frases: 1.328.744
- Quantidade de tokens no corpus usado no treino: 17.212.074
- Quantidade de palavras que entraram para o treinamento: 15.714.507
- Quantidade de tokens no vocabul√°rio: 30.356
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_4_HST_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 555
- Quantidade de frases: 1.684.074
- Quantidade de tokens no corpus usado no treino: 22.107.717
- Quantidade de palavras que entraram para o treinamento: 20.248.333
- Quantidade de tokens no vocabul√°rio: 35.688
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 100
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---


</details>


## ü§ñ WOKE SAUDE-CORPO-03-10

- Quantidade de m√∫ltiplos treinos para gera√ß√£o de modelo base: **1260**

<details>
  <summary><b>Mais informa√ß√µes <i>(clique para expandir)</i></b></summary>
  <br>
  <ul><li><b>Quantidade de trabalhos contemplados no total: 3.054</b></li>
  <li><b>Quantidade de cole√ß√µes contempladas: 15</b>
  <br>
    <details>
      <summary>Visualizar cole√ß√µes utilizadas <i>(clique para expandir)</i></summary>
        <ul><li>Biologia_Celular_e_do_Desenvolvimento</li> <li>Biotecnologia_e_Biociencias</li> <li>Ciencias_da_Reabilitacao</li> <li>Ciencias_Medicas</li> <li>Cuidados_Intensivos_e_Paliativos_Mestrado_Profissional</li> <li>Educacao_Fisica</li> <li>Enfermagem</li> <li>Gestao_do_Cuidado_em_Enfermagem</li> <li>Gestao_do_Cuidado_em_Enfermagem_Mestrado_Profissional</li> <li>Medicina_Veterinaria_Convencional_e_Integrativa</li> <li>Neurociencias</li> <li>Saude_Coletiva</li> <li>Saude_Mental_e_Atencao_Psicossocial_Mestrado_Profissional</li> <li>Saude_Publica</li> <li>Programa_de_Pos_Graduacao_Multidisciplinar_em_Saude_Mestrado_Profissional</li></ul>
    </details>
  </li></ul>

### Hyperlinks para os temas desta p√°gina

- [Incremental](#incremental)
  - [WOKE SAUDE-CORPO MODELO 1](#woke-saude-corpo-modelo-1)
  - [WOKE SAUDE-CORPO MODELO 2](#woke-saude-corpo-modelo-2)
  - [WOKE SAUDE-CORPO MODELO 3](#woke-saude-corpo-modelo-3)


- [Temporal](#temporal)
  - [WOKE SAUDE-CORPO MODELO 1](#woke-saude-corpo-modelo-1-1)
  - [WOKE SAUDE-CORPO MODELO 2](#woke-saude-corpo-modelo-2-1)
  - [WOKE SAUDE-CORPO MODELO 3](#woke-saude-corpo-modelo-3-1)


## Incremental
### WOKE SAUDE-CORPO MODELO 1
#### WOKE_1_SAUDE-CORPO_2003_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 691
- Quantidade de frases: 947.942
- Quantidade de tokens no corpus usado no treino: 13.614.492
- Quantidade de palavras que entraram para o treinamento: 12.740.967
- Quantidade de tokens no vocabul√°rio: 35.655
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

#### WOKE_1_SAUDE-CORPO_2011_2013_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.134
- Quantidade de frases: 524.569
- Quantidade de tokens no corpus usado no treino: 7.419.591
- Quantidade de palavras que entraram para o treinamento: 19.588.648
- Quantidade de tokens no vocabul√°rio: 40.711
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

#### WOKE_1_SAUDE-CORPO_2014_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.760
- Quantidade de frases: 810.178
- Quantidade de tokens no corpus usado no treino: 11.357.632
- Quantidade de palavras que entraram para o treinamento: 30.101.935
- Quantidade de tokens no vocabul√°rio: 48.728
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

#### WOKE_1_SAUDE-CORPO_2017_2019_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 2.380
- Quantidade de frases: 783.823
- Quantidade de tokens no corpus usado no treino: 11.007.741
- Quantidade de palavras que entraram para o treinamento: 40.234.412
- Quantidade de tokens no vocabul√°rio: 56.172
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

#### WOKE_1_SAUDE-CORPO_2020_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 3.054
- Quantidade de frases: 839.403
- Quantidade de tokens no corpus usado no treino: 11.684.040
- Quantidade de palavras que entraram para o treinamento: 50.967.179
- Quantidade de tokens no vocabul√°rio: 62.939
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

### WOKE SAUDE-CORPO MODELO 2
#### WOKE_2_SAUDE-CORPO_2003_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 691
- Quantidade de frases: 947.942
- Quantidade de tokens no corpus usado no treino: 13.614.492
- Quantidade de palavras que entraram para o treinamento: 12.740.967
- Quantidade de tokens no vocabul√°rio: 35.655
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

#### WOKE_2_SAUDE-CORPO_2011_2013_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.134
- Quantidade de frases: 524.569
- Quantidade de tokens no corpus usado no treino: 7.419.591
- Quantidade de palavras que entraram para o treinamento: 19.588.648
- Quantidade de tokens no vocabul√°rio: 40.711
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

#### WOKE_2_SAUDE-CORPO_2014_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.760
- Quantidade de frases: 810.178
- Quantidade de tokens no corpus usado no treino: 11.357.632
- Quantidade de palavras que entraram para o treinamento: 30.101.935
- Quantidade de tokens no vocabul√°rio: 48.728
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

#### WOKE_2_SAUDE-CORPO_2017_2019_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 2.380
- Quantidade de frases: 783.823
- Quantidade de tokens no corpus usado no treino: 11.007.741
- Quantidade de palavras que entraram para o treinamento: 40.234.412
- Quantidade de tokens no vocabul√°rio: 56.172
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

#### WOKE_2_SAUDE-CORPO_2020_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 3.054
- Quantidade de frases: 839.403
- Quantidade de tokens no corpus usado no treino: 11.684.040
- Quantidade de palavras que entraram para o treinamento: 50.967.179
- Quantidade de tokens no vocabul√°rio: 62.939
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

### WOKE SAUDE-CORPO MODELO 3
#### WOKE_3_SAUDE-CORPO_2003_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 691
- Quantidade de frases: 947.942
- Quantidade de tokens no corpus usado no treino: 13.614.492
- Quantidade de palavras que entraram para o treinamento: 12.487.497
- Quantidade de tokens no vocabul√°rio: 23.354
###### Par√¢metros
- Modo: CBOW
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_3_SAUDE-CORPO_2011_2013_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.134
- Quantidade de frases: 524.569
- Quantidade de tokens no corpus usado no treino: 7.419.591
- Quantidade de palavras que entraram para o treinamento: 19.172.566
- Quantidade de tokens no vocabul√°rio: 25.798
###### Par√¢metros
- Modo: CBOW
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_3_SAUDE-CORPO_2014_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.760
- Quantidade de frases: 810.178
- Quantidade de tokens no corpus usado no treino: 11.357.632
- Quantidade de palavras que entraram para o treinamento: 29.452.598
- Quantidade de tokens no vocabul√°rio: 29.995
###### Par√¢metros
- Modo: CBOW
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_3_SAUDE-CORPO_2017_2019_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 2.380
- Quantidade de frases: 783.823
- Quantidade de tokens no corpus usado no treino: 11.007.741
- Quantidade de palavras que entraram para o treinamento: 39.340.812
- Quantidade de tokens no vocabul√°rio: 33.676
###### Par√¢metros
- Modo: CBOW
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_3_SAUDE-CORPO_2020_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 3.054
- Quantidade de frases: 839.403
- Quantidade de tokens no corpus usado no treino: 11.684.040
- Quantidade de palavras que entraram para o treinamento: 49.823.408
- Quantidade de tokens no vocabul√°rio: 37.020
###### Par√¢metros
- Modo: CBOW
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---


## Temporal
### WOKE SAUDE-CORPO MODELO 1
#### WOKE_1_SAUDE-CORPO_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 691
- Quantidade de frases: 947.942
- Quantidade de tokens no corpus usado no treino: 13.614.492
- Quantidade de palavras que entraram para o treinamento: 12.740.967
- Quantidade de tokens no vocabul√°rio: 35.655
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

#### WOKE_1_SAUDE-CORPO_2003_2013_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.134
- Quantidade de frases: 1.472.511
- Quantidade de tokens no corpus usado no treino: 21.034.083
- Quantidade de palavras que entraram para o treinamento: 19.753.598
- Quantidade de tokens no vocabul√°rio: 48.341
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

#### WOKE_1_SAUDE-CORPO_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.760
- Quantidade de frases: 2.282.689
- Quantidade de tokens no corpus usado no treino: 32.391.715
- Quantidade de palavras que entraram para o treinamento: 30.522.336
- Quantidade de tokens no vocabul√°rio: 64.903
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

#### WOKE_1_SAUDE-CORPO_2003_2019_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 2.380
- Quantidade de frases: 3.066.512
- Quantidade de tokens no corpus usado no treino: 43.399.456
- Quantidade de palavras que entraram para o treinamento: 40.937.663
- Quantidade de tokens no vocabul√°rio: 80.485
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

#### WOKE_1_SAUDE-CORPO_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 3.054
- Quantidade de frases: 3.905.915
- Quantidade de tokens no corpus usado no treino: 55.083.496
- Quantidade de palavras que entraram para o treinamento: 51.964.360
- Quantidade de tokens no vocabul√°rio: 95.329
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

### WOKE SAUDE-CORPO MODELO 2
#### WOKE_2_SAUDE-CORPO_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 691
- Quantidade de frases: 947.942
- Quantidade de tokens no corpus usado no treino: 13.614.492
- Quantidade de palavras que entraram para o treinamento: 12.740.967
- Quantidade de tokens no vocabul√°rio: 35.655
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

#### WOKE_2_SAUDE-CORPO_2003_2013_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.134
- Quantidade de frases: 1.472.511
- Quantidade de tokens no corpus usado no treino: 21.034.083
- Quantidade de palavras que entraram para o treinamento: 19.753.598
- Quantidade de tokens no vocabul√°rio: 48.341
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

#### WOKE_2_SAUDE-CORPO_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.760
- Quantidade de frases: 2.282.689
- Quantidade de tokens no corpus usado no treino: 32.391.715
- Quantidade de palavras que entraram para o treinamento: 30.522.336
- Quantidade de tokens no vocabul√°rio: 64.903
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

#### WOKE_2_SAUDE-CORPO_2003_2019_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 2.380
- Quantidade de frases: 3.066.512
- Quantidade de tokens no corpus usado no treino: 43.399.456
- Quantidade de palavras que entraram para o treinamento: 40.937.663
- Quantidade de tokens no vocabul√°rio: 80.485
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

#### WOKE_2_SAUDE-CORPO_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 3.054
- Quantidade de frases: 3.905.915
- Quantidade de tokens no corpus usado no treino: 55.083.496
- Quantidade de palavras que entraram para o treinamento: 51.964.360
- Quantidade de tokens no vocabul√°rio: 95.329
###### Par√¢metros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 15


---

### WOKE SAUDE-CORPO MODELO 3
#### WOKE_3_SAUDE-CORPO_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 691
- Quantidade de frases: 947.942
- Quantidade de tokens no corpus usado no treino: 13.614.492
- Quantidade de palavras que entraram para o treinamento: 12.487.497
- Quantidade de tokens no vocabul√°rio: 23.354
###### Par√¢metros
- Modo: CBOW
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_3_SAUDE-CORPO_2003_2013_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.134
- Quantidade de frases: 1.472.511
- Quantidade de tokens no corpus usado no treino: 21.034.083
- Quantidade de palavras que entraram para o treinamento: 19.400.078
- Quantidade de tokens no vocabul√°rio: 31.166
###### Par√¢metros
- Modo: CBOW
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_3_SAUDE-CORPO_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.760
- Quantidade de frases: 2.282.689
- Quantidade de tokens no corpus usado no treino: 32.391.715
- Quantidade de palavras que entraram para o treinamento: 30.037.587
- Quantidade de tokens no vocabul√°rio: 41.302
###### Par√¢metros
- Modo: CBOW
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_3_SAUDE-CORPO_2003_2019_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 2.380
- Quantidade de frases: 3.066.512
- Quantidade de tokens no corpus usado no treino: 43.399.456
- Quantidade de palavras que entraram para o treinamento: 40.335.099
- Quantidade de tokens no vocabul√°rio: 51.148
###### Par√¢metros
- Modo: CBOW
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_3_SAUDE-CORPO_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 3.054
- Quantidade de frases: 3.905.915
- Quantidade de tokens no corpus usado no treino: 55.083.496
- Quantidade de palavras que entraram para o treinamento: 51.244.642
- Quantidade de tokens no vocabul√°rio: 60.168
###### Par√¢metros
- Modo: CBOW
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---


</details>

<br>
<br>
‚ùó <i>Observa√ß√£o: A nomenclatura das cole√ß√µes contempladas para cada treinamento est√° no formato utilizado para nomear os arquivos, por isso alguns caracteres especiais como acentos e "√ß" n√£o constam no nome.</i>