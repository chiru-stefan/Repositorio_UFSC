# WOKE - CFH

- **Quantidade de coleções contempladas: 12**
- **Quantidade de trabalhos contemplados no total: 3.554**

## Hyperlinks para os temas desta página

- [Incremental](#incremental)
  - [WOKE CFH MODELO 1](#woke-cfh-modelo-1)
  - [WOKE CFH MODELO 2](#woke-cfh-modelo-2)
  - [WOKE CFH MODELO 3](#woke-cfh-modelo-3)


- [Temporal](#temporal)
  - [WOKE CFH MODELO 1](#woke-cfh-modelo-1-1)
  - [WOKE CFH MODELO 2](#woke-cfh-modelo-2-1)
  - [WOKE CFH MODELO 3](#woke-cfh-modelo-3-1)


## Incremental
### WOKE CFH MODELO 1
#### WOKE_1_CFH_2003_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.074
- Quantidade de frases: 2.354.048
- Quantidade de tokens no corpus usado no treino: 34.137.504
- Quantidade de palavras que entraram para o treinamento: 31.962.981
- Quantidade de tokens no vocabulário: 41.628
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_1_CFH_2011_2013_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.608
- Quantidade de frases: 1.191.385
- Quantidade de tokens no corpus usado no treino: 17.669.890
- Quantidade de palavras que entraram para o treinamento: 48.473.069
- Quantidade de tokens no vocabulário: 44.563
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_1_CFH_2014_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 2.217
- Quantidade de frases: 1.399.659
- Quantidade de tokens no corpus usado no treino: 20.441.299
- Quantidade de palavras que entraram para o treinamento: 67.510.694
- Quantidade de tokens no vocabulário: 48.331
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_1_CFH_2017_2019_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 2.888
- Quantidade de frases: 1.538.214
- Quantidade de tokens no corpus usado no treino: 22.951.565
- Quantidade de palavras que entraram para o treinamento: 88.948.727
- Quantidade de tokens no vocabulário: 52.545
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_1_CFH_2020_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 3.554
- Quantidade de frases: 1.502.951
- Quantidade de tokens no corpus usado no treino: 22.512.208
- Quantidade de palavras que entraram para o treinamento: 109.806.862
- Quantidade de tokens no vocabulário: 57.032
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

### WOKE CFH MODELO 2
#### WOKE_2_CFH_2003_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.074
- Quantidade de frases: 2.354.048
- Quantidade de tokens no corpus usado no treino: 34.137.504
- Quantidade de palavras que entraram para o treinamento: 31.631.016
- Quantidade de tokens no vocabulário: 32.441
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_2_CFH_2011_2013_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.608
- Quantidade de frases: 1.191.385
- Quantidade de tokens no corpus usado no treino: 17.669.890
- Quantidade de palavras que entraram para o treinamento: 47.968.421
- Quantidade de tokens no vocabulário: 34.396
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_2_CFH_2014_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 2.217
- Quantidade de frases: 1.399.659
- Quantidade de tokens no corpus usado no treino: 20.441.299
- Quantidade de palavras que entraram para o treinamento: 66.796.682
- Quantidade de tokens no vocabulário: 36.894
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_2_CFH_2017_2019_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 2.888
- Quantidade de frases: 1.538.214
- Quantidade de tokens no corpus usado no treino: 22.951.565
- Quantidade de palavras que entraram para o treinamento: 88.003.531
- Quantidade de tokens no vocabulário: 39.709
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_2_CFH_2020_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 3.554
- Quantidade de frases: 1.502.951
- Quantidade de tokens no corpus usado no treino: 22.512.208
- Quantidade de palavras que entraram para o treinamento: 108.622.050
- Quantidade de tokens no vocabulário: 42.681
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

### WOKE CFH MODELO 3
#### WOKE_3_CFH_2003_2010_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.074
- Quantidade de frases: 2.354.048
- Quantidade de tokens no corpus usado no treino: 34.137.504
- Quantidade de palavras que entraram para o treinamento: 32.249.400
- Quantidade de tokens no vocabulário: 53.592
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---

#### WOKE_3_CFH_2011_2013_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 1.608
- Quantidade de frases: 1.191.385
- Quantidade de tokens no corpus usado no treino: 17.669.890
- Quantidade de palavras que entraram para o treinamento: 48.908.235
- Quantidade de tokens no vocabulário: 58.091
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---

#### WOKE_3_CFH_2014_2016_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 2.217
- Quantidade de frases: 1.399.659
- Quantidade de tokens no corpus usado no treino: 20.441.299
- Quantidade de palavras que entraram para o treinamento: 68.131.281
- Quantidade de tokens no vocabulário: 63.899
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---

#### WOKE_3_CFH_2017_2019_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 2.888
- Quantidade de frases: 1.538.214
- Quantidade de tokens no corpus usado no treino: 22.951.565
- Quantidade de palavras que entraram para o treinamento: 89.770.760
- Quantidade de tokens no vocabulário: 70.237
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---

#### WOKE_3_CFH_2020_2024_w2v_inc
##### Contagens
- Quantidade de trabalhos contemplados: 3.554
- Quantidade de frases: 1.502.951
- Quantidade de tokens no corpus usado no treino: 22.512.208
- Quantidade de palavras que entraram para o treinamento: 110.836.691
- Quantidade de tokens no vocabulário: 76.964
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---


## Temporal
### WOKE CFH MODELO 1
#### WOKE_1_CFH_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.074
- Quantidade de frases: 2.354.048
- Quantidade de tokens no corpus usado no treino: 34.137.504
- Quantidade de palavras que entraram para o treinamento: 31.962.981
- Quantidade de tokens no vocabulário: 41.628
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_1_CFH_2003_2013_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.608
- Quantidade de frases: 3.545.433
- Quantidade de tokens no corpus usado no treino: 51.807.394
- Quantidade de palavras que entraram para o treinamento: 48.830.872
- Quantidade de tokens no vocabulário: 53.418
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_1_CFH_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 2.217
- Quantidade de frases: 4.945.092
- Quantidade de tokens no corpus usado no treino: 72.248.693
- Quantidade de palavras que entraram para o treinamento: 68.351.277
- Quantidade de tokens no vocabulário: 65.992
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_1_CFH_2003_2019_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 2.888
- Quantidade de frases: 6.483.306
- Quantidade de tokens no corpus usado no treino: 95.200.258
- Quantidade de palavras que entraram para o treinamento: 90.343.370
- Quantidade de tokens no vocabulário: 78.479
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

#### WOKE_1_CFH_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 3.554
- Quantidade de frases: 7.986.257
- Quantidade de tokens no corpus usado no treino: 117.712.466
- Quantidade de palavras que entraram para o treinamento: 111.787.322
- Quantidade de tokens no vocabulário: 90.891
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 200
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 30


---

### WOKE CFH MODELO 2
#### WOKE_2_CFH_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.074
- Quantidade de frases: 2.354.048
- Quantidade de tokens no corpus usado no treino: 34.137.504
- Quantidade de palavras que entraram para o treinamento: 31.631.016
- Quantidade de tokens no vocabulário: 32.441
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_2_CFH_2003_2013_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.608
- Quantidade de frases: 3.545.433
- Quantidade de tokens no corpus usado no treino: 51.807.394
- Quantidade de palavras que entraram para o treinamento: 48.404.895
- Quantidade de tokens no vocabulário: 41.650
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_2_CFH_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 2.217
- Quantidade de frases: 4.945.092
- Quantidade de tokens no corpus usado no treino: 72.248.693
- Quantidade de palavras que entraram para o treinamento: 67.823.884
- Quantidade de tokens no vocabulário: 51.415
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_2_CFH_2003_2019_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 2.888
- Quantidade de frases: 6.483.306
- Quantidade de tokens no corpus usado no treino: 95.200.258
- Quantidade de palavras que entraram para o treinamento: 89.708.563
- Quantidade de tokens no vocabulário: 60.901
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

#### WOKE_2_CFH_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 3.554
- Quantidade de frases: 7.986.257
- Quantidade de tokens no corpus usado no treino: 117.712.466
- Quantidade de palavras que entraram para o treinamento: 111.037.755
- Quantidade de tokens no vocabulário: 70.118
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 300
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 45


---

### WOKE CFH MODELO 3
#### WOKE_3_CFH_2003_2010_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.074
- Quantidade de frases: 2.354.048
- Quantidade de tokens no corpus usado no treino: 34.137.504
- Quantidade de palavras que entraram para o treinamento: 32.249.400
- Quantidade de tokens no vocabulário: 53.592
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---

#### WOKE_3_CFH_2003_2013_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 1.608
- Quantidade de frases: 3.545.433
- Quantidade de tokens no corpus usado no treino: 51.807.394
- Quantidade de palavras que entraram para o treinamento: 49.204.283
- Quantidade de tokens no vocabulário: 69.026
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---

#### WOKE_3_CFH_2003_2016_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 2.217
- Quantidade de frases: 4.945.092
- Quantidade de tokens no corpus usado no treino: 72.248.693
- Quantidade de palavras que entraram para o treinamento: 68.823.075
- Quantidade de tokens no vocabulário: 85.736
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---

#### WOKE_3_CFH_2003_2019_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 2.888
- Quantidade de frases: 6.483.306
- Quantidade de tokens no corpus usado no treino: 95.200.258
- Quantidade de palavras que entraram para o treinamento: 90.917.767
- Quantidade de tokens no vocabulário: 102.478
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---

#### WOKE_3_CFH_2003_2024_w2v_tmp
##### Contagens
- Quantidade de trabalhos contemplados: 3.554
- Quantidade de frases: 7.986.257
- Quantidade de tokens no corpus usado no treino: 117.712.466
- Quantidade de palavras que entraram para o treinamento: 112.464.060
- Quantidade de tokens no vocabulário: 119.178
###### Parâmetros
- Modo: Skip-Gram
- vector_size: 150
- negative: 10
- window: 12
- epochs 5
- alpha 0.025
- min_count: 20


---
