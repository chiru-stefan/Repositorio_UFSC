{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hNMCsrO9JuO"
      },
      "source": [
        "Link para melhor visualização do Notebook em seu ambiente de execução: [Notebook Colab](https://colab.research.google.com/drive/1-zQJORN5Np0CxNlRQilhmLJczn7llpqR?usp=sharing)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Notebook desenvolvido para padronizar/formatar o arquivo de analogias para o formato esperado nas execuções de validação dos treinamentos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsJzrF2x9nD_"
      },
      "source": [
        "# Config. de ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7q1XQ1U2oIV",
        "outputId": "3d518ff1-9282-49d1-ff32-fb7cf1e726ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ferramentas-basicas-pln\n",
            "  Downloading ferramentas_basicas_pln-0.9.9.8-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from ferramentas-basicas-pln) (2023.12.25)\n",
            "Installing collected packages: ferramentas-basicas-pln\n",
            "Successfully installed ferramentas-basicas-pln-0.9.9.8\n"
          ]
        }
      ],
      "source": [
        "!pip install ferramentas-basicas-pln -U\n",
        "from ferramentas_basicas_pln import removerCaracteresEspeciais,removerCaracteresEstranhos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHHRwIVGCvol"
      },
      "source": [
        "# Analogias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpqt7cT81ykW"
      },
      "outputs": [],
      "source": [
        "with open(r'/content/analogias_woke_atualizadas_final.txt','r',encoding='utf-8') as f:\n",
        "  txt_analogias_basicas = removerCaracteresEstranhos(f.read())\n",
        "\n",
        "analogias = []\n",
        "\n",
        "for linha in txt_analogias_basicas.split('\\n'):\n",
        "  if linha.strip() != '':\n",
        "    if linha.startswith(':'):\n",
        "      analogias.append('\\n'+linha.lower())\n",
        "    else:\n",
        "      analogia = []\n",
        "      if ',' in linha: # Usando \",\" como separador\n",
        "        palavras = linha.split(',')\n",
        "        for palavra in palavras:\n",
        "          if '|' in palavra and palavra == palavras[-1]:\n",
        "            palavra_ = []\n",
        "            for resposta in palavra.split('|'):\n",
        "              resposta = resposta.strip()\n",
        "              resposta = removerCaracteresEspeciais(resposta,string_caracteres_especiais='''!\"#$%&'()*+,./:;<=>?@[\\]^`{|}~''')\n",
        "              resposta = resposta.replace(' ','_')\n",
        "              palavra_.append(resposta)\n",
        "            palavra = '|'.join(palavra_)\n",
        "          else:\n",
        "            palavra = palavra.strip()\n",
        "            palavra = removerCaracteresEspeciais(palavra,string_caracteres_especiais='''!\"#$%&'()*+,./:;<=>?@[\\]^`{|}~''')\n",
        "            palavra = palavra.replace(' ','_')\n",
        "          analogia.append(palavra.lower())\n",
        "      else:\n",
        "        palavras = linha.split(' ') # Usando espaço como separador\n",
        "        for palavra in palavras:\n",
        "          if '|' in palavra and palavra == palavras[-1]:\n",
        "            palavra_ = []\n",
        "            for resposta in palavra.split('|'):\n",
        "              resposta = resposta.strip()\n",
        "              resposta = removerCaracteresEspeciais(resposta,string_caracteres_especiais='''!\"#$%&'()*+,./:;<=>?@[\\]^`{|}~''')\n",
        "              resposta = resposta.replace(' ','_')\n",
        "              palavra_.append(resposta)\n",
        "            palavra = '|'.join(palavra_)\n",
        "          else:\n",
        "            palavra = palavra.strip()\n",
        "            palavra = removerCaracteresEspeciais(palavra,string_caracteres_especiais='''!\"#$%&'()*+,./:;<=>?@[\\]^`{|}~''')\n",
        "            palavra = palavra.replace(' ','_')\n",
        "          analogia.append(palavra.lower())\n",
        "      if len(analogia) == 4:\n",
        "        analogia_formatada = ','.join(analogia)\n",
        "        if analogia_formatada not in analogias:\n",
        "          analogias.append(analogia_formatada)\n",
        "          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86sNRX5W-m-h",
        "outputId": "17a18315-b5d5-4643-e66d-4a222ad7eaca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1439\n",
            "1439\n"
          ]
        }
      ],
      "source": [
        "print(len(set(analogias)))\n",
        "print(len(analogias))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWa2xSoR4n2z"
      },
      "outputs": [],
      "source": [
        "txt_analogias = '\\n'.join(analogias)\n",
        "with open(r'/content/analogias_woke_atualizadas_final_ATUALIZADO.txt','w',encoding='utf-8') as f:\n",
        "  f.write(txt_analogias)\n",
        "print(txt_analogias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rUxNY1qC07H"
      },
      "source": [
        "# Similaridade positiva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfgY21jiC16d"
      },
      "outputs": [],
      "source": [
        "with open(r'/content/similaridades_positiva_woke_atualizadas_final.txt','r',encoding='utf-8') as f:\n",
        "  txt_similaridades_basicas = removerCaracteresEstranhos(f.read())\n",
        "\n",
        "similaridades = []\n",
        "\n",
        "for linha in txt_similaridades_basicas.split('\\n'):\n",
        "  if linha.strip() != '':\n",
        "    if linha.startswith(':'):\n",
        "      similaridades.append('\\n'+linha.lower())\n",
        "    else:\n",
        "      similaridade = []\n",
        "      if ',' in linha: # Usando \",\" como separador\n",
        "        palavras = linha.split(',')\n",
        "        for palavra in palavras:\n",
        "          if '|' in palavra and palavra == palavras[-1]:\n",
        "            palavra_ = []\n",
        "            for resposta in palavra.split('|'):\n",
        "              resposta = resposta.strip()\n",
        "              resposta = removerCaracteresEspeciais(resposta,string_caracteres_especiais='''!\"#$%&'()*+,./:;<=>?@[\\]^`{|}~''')\n",
        "              resposta = resposta.replace(' ','_')\n",
        "              palavra_.append(resposta)\n",
        "            palavra = '|'.join(palavra_)\n",
        "          else:\n",
        "            palavra = palavra.strip()\n",
        "            palavra = removerCaracteresEspeciais(palavra,string_caracteres_especiais='''!\"#$%&'()*+,./:;<=>?@[\\]^`{|}~''')\n",
        "            palavra = palavra.replace(' ','_')\n",
        "          similaridade.append(palavra.lower())\n",
        "      else:\n",
        "        palavras = linha.split(' ') # Usando espaço como separador\n",
        "        for palavra in palavras:\n",
        "          if '|' in palavra and palavra == palavras[-1]:\n",
        "            palavra_ = []\n",
        "            for resposta in palavra.split('|'):\n",
        "              resposta = resposta.strip()\n",
        "              resposta = removerCaracteresEspeciais(resposta,string_caracteres_especiais='''!\"#$%&'()*+,./:;<=>?@[\\]^`{|}~''')\n",
        "              resposta = resposta.replace(' ','_')\n",
        "              palavra_.append(resposta)\n",
        "            palavra = '|'.join(palavra_)\n",
        "          else:\n",
        "            palavra = palavra.strip()\n",
        "            palavra = removerCaracteresEspeciais(palavra,string_caracteres_especiais='''!\"#$%&'()*+,./:;<=>?@[\\]^`{|}~''')\n",
        "            palavra = palavra.replace(' ','_')\n",
        "          similaridade.append(palavra.lower())\n",
        "      if len(similaridade) == 2:\n",
        "        similaridade_formatada = ','.join(similaridade)\n",
        "        if similaridade_formatada not in similaridades:\n",
        "          similaridades.append(similaridade_formatada)\n",
        "          "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rpdAeu4DTj8"
      },
      "source": [
        "# Similaridade negativa (contra-conceitos/antônimos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJiXhRSWDWG1"
      },
      "outputs": [],
      "source": [
        "with open(r'/content/contra-conceitos_WOKE.txt','r',encoding='utf-8') as f:\n",
        "  txt_similaridades_basicas = removerCaracteresEstranhos(f.read())\n",
        "\n",
        "similaridades = []\n",
        "\n",
        "for linha in txt_similaridades_basicas.split('\\n'):\n",
        "  if linha.strip() != '':\n",
        "    if linha.startswith(':'):\n",
        "      similaridades.append('\\n'+linha.lower())\n",
        "    else:\n",
        "      similaridade = []\n",
        "      if ',' in linha: # Usando \",\" como separador\n",
        "        palavras = linha.split(',')\n",
        "        for palavra in palavras:\n",
        "          if '|' in palavra and palavra == palavras[-1]:\n",
        "            palavra_ = []\n",
        "            for resposta in palavra.split('|'):\n",
        "              resposta = resposta.strip()\n",
        "              resposta = removerCaracteresEspeciais(resposta,string_caracteres_especiais='''!\"#$%&'()*+,./:;<=>?@[\\]^`{|}~''')\n",
        "              resposta = resposta.replace(' ','_')\n",
        "              palavra_.append(resposta)\n",
        "            palavra = '|'.join(palavra_)\n",
        "          else:\n",
        "            palavra = palavra.strip()\n",
        "            palavra = removerCaracteresEspeciais(palavra,string_caracteres_especiais='''!\"#$%&'()*+,./:;<=>?@[\\]^`{|}~''')\n",
        "            palavra = palavra.replace(' ','_')\n",
        "          similaridade.append(palavra.lower())\n",
        "      else:\n",
        "        palavras = linha.split(' ') # Usando espaço como separador\n",
        "        for palavra in palavras:\n",
        "          if '|' in palavra and palavra == palavras[-1]:\n",
        "            palavra_ = []\n",
        "            for resposta in palavra.split('|'):\n",
        "              resposta = resposta.strip()\n",
        "              resposta = removerCaracteresEspeciais(resposta,string_caracteres_especiais='''!\"#$%&'()*+,./:;<=>?@[\\]^`{|}~''')\n",
        "              resposta = resposta.replace(' ','_')\n",
        "              palavra_.append(resposta)\n",
        "            palavra = '|'.join(palavra_)\n",
        "          else:\n",
        "            palavra = palavra.strip()\n",
        "            palavra = removerCaracteresEspeciais(palavra,string_caracteres_especiais='''!\"#$%&'()*+,./:;<=>?@[\\]^`{|}~''')\n",
        "            palavra = palavra.replace(' ','_')\n",
        "          similaridade.append(palavra.lower())\n",
        "      if len(similaridade) == 2:\n",
        "        similaridade_formatada = ','.join(similaridade)\n",
        "        if similaridade_formatada not in similaridades:\n",
        "          similaridades.append(similaridade_formatada)\n",
        "          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KbW500qDpRh",
        "outputId": "d3aaa59f-d72c-4de3-f580-8e7d8b34e13c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "democracia,ditadura|ditaduras|autoritarismo|totalitarismo|nazismo|fascismo|censura|opressão\n",
            "liberdade,opressão|restrição|censura|prisão\n",
            "paz,guerra|conflito|desordem|caos\n",
            "ordem,desordem|caos|incerteza\n",
            "certeza,incerteza\n",
            "amor,ódio|raiva\n",
            "bem,mal|ruim\n",
            "verdade,mentira|falso|falsa|falsidade\n",
            "justiça,injustiça|trapaça\n",
            "igualdade,desigualdade\n",
            "tolerância,intolerância\n",
            "beleza,feiura\n",
            "harmonia,desharmonia\n",
            "conhecimento,ignorância\n",
            "liberalismo,conservadorismo\n",
            "riqueza,pobreza\n",
            "ética,antiética|antiético|antimoralidade|aética|anética|imoralidade|indecência\n",
            "ético,antiético|antiética|antimoralidade|aética|anética|imoralidade|indecência\n",
            "honra,desonra\n",
            "virtude,defeito|vício|fraqueza|desvirtude\n",
            "sorte,azar\n",
            "egoísta,altuísta|altruístico|filantropo|finaltrópico|humanitário|empático|humanitarista|generoso|caridoso|bondoso\n",
            "simples,complexo|difícil|complicado|confuso|incompreensível|duro|enigmático|formal|rebuscado|robusto\n",
            "dormir,acordar|despertar\n",
            "falar,calar\n",
            "elogiar,xingar|menosprezar\n",
            "respeitar,desrespeitar\n"
          ]
        }
      ],
      "source": [
        "txt_antonimos = '\\n'.join(similaridades)\n",
        "with open(r'/content/contra-conceitos_WOKE.txt','w',encoding='utf-8') as f:\n",
        "  f.write(txt_antonimos)\n",
        "print(txt_antonimos)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7rUxNY1qC07H",
        "4rpdAeu4DTj8"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
