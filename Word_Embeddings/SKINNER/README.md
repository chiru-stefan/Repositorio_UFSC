# üîç Semantic Knowledge and Interpretation Navigator for Nurturing Exact References

## SKINNER - WOKE - UFSC 

O algoritmo Semantic Knowledge and Interpretation Navigator for Nurturing Exact References (SKINNER) foi desenvolvido com o intuito de clarear, na medida do poss√≠vel, as constru√ß√µes de contexto dos vetores de palavras atribu√≠das dentro de algumas etapas do algoritmo Word2Vec com base na co-ocorr√™ncia de palavras e suas respectivas frequ√™ncias. Para tal feito, pensou-se em replicar tais etapas e armazenar as informa√ß√µes obtidas.
Sendo assim, destaca-se que o escopo de an√°lise com base no SKINNER se d√° por meio de modelos individuais, ou seja, devemos escolher um modelo para ent√£o analisar o processo de constru√ß√£o de contexto com base na co-ocorr√™ncia das palavras utilizadas para alimentar seu treinamento.

Podemos resumir o desenvolvimento deste algoritmo da seguinte forma:
- **Coleta de informa√ß√µes do modelo utilizado**: Ap√≥s escolher o modelo que ter√° sua an√°lise disponibilizada, verifica-se qual foi o tamanho da janela de contexto utilizada no treinamento, bem como os tokens presentes no vocabul√°rio do modelo e o intervalo de datas contemplado pelo treinamento do mesmo.
- **Coleta de informa√ß√µes a respeito da co-ocorr√™ncia de palavras no corpus**: Depois de obter o vocabul√°rio (palavras √∫nicas que entraram para o treinamento) e o tamanho da janela (quantidade de tokens que ser√£o analisados na frase toda ao redor de um token central/alvo para montar contexto), pode-se partir para constru√ß√£o de contexto com base nas frases presentes no corpus (no recorte temporal utilizado no treino) e nas palavras que entraram para o treinamento dentro dessas frases. Al√©m da constru√ß√£o do contexto propriamente dita, os arquivos foram estruturados de tal forma que preservou-se a estrutura√ß√£o das pastas que armazenam os arquivos de textos no corpus de documentos, podendo assim organiz√°-lo com base na cole√ß√£o, trabalho e nos metadados do trabalho (assuntos, link para p√°gina no reposit√≥rio e link para o PDF que teve seu texto extra√≠do).
- **Constru√ß√£o de contexto**: Ap√≥s feita a gera√ß√£o dos arquivos referentes as informa√ß√µes de co-ocorr√™ncia (cada arquivo fazendo referencia a uma cole√ß√£o/curso utilizada no treinamento), pode-se ent√£o navegar entre eles construindo o contexto para um determinado conjunto de tokens.
- **Gera√ß√£o de PDF**: E, por fim, depois de constru√≠do contexto para os tokens que deseja-se analisar, pode-se, ent√£o, gerar o PDF contendo todas as informa√ß√µes organizadas.

### Exemplo
Para melhor compreender o processo de constru√ß√£o de contexto, imagine um exemplo em que o modelo que se queira analisar tem as seguintes caracter√≠sticas:
-  Foi treinado com uma janela de tamanho 2;
- Possui um vocabul√°rio com esses tokens: "g√™nero","import√¢ncia","textos","explora","textual","inclus√£o","artigo", "aborda", "borboleta", "sof√°".

Agora imagine que estamos no meio de uma an√°lise de um trabalho e vamos passar pela seguinte frase:

"O artigo explora a inclus√£o de g√™nero em textos dentro dos estudos de g√™nero."

*Observa√ß√£o: a frase de exemplo n√£o est√° tokenizada t√£o pouco pr√©-processada, foi deixada em seu "formato cru" apenas para fins did√°ticos, pois as frases no corpus de textos pr√©-processado utilizado para os treinamentos dos modelos WOKE se apresentariam de outra forma, removendo stopwords, lematizando verbos, etc.*

Voltando √† an√°lise, como estamos interessados apenas nos tokens que, de fato, entraram para o treinamento do modelo analisado, filtramos a frase para apenas conter os tokens que existem no modelo:

"artigo explora inclus√£o g√™nero textos g√™nero"

Feita a filtragem da frase passamos a analisar token por token de forma a deix√°-lo como token central/alvo na an√°lise, buscando assim as palavras que o cercam na janela usada pelo treinamento:

- artigo:
    - explora: 1
    - inclus√£o: 1
- explora:
    - artigo: 1
    - inclus√£o: 1
    - g√™nero: 1
- inclus√£o:
    - artigo: 1
    - explora: 1
    - g√™nero: 1
    - textos: 1
- g√™nero:
    - explora: 1
    - inclus√£o: 1
    - textos: 2

Note que os itens listados a cima fornecem a informa√ß√£o dos tokens centrais e seus respectivos tokens de contexto com suas respectivas frequ√™ncias de ocorr√™ncias. Al√©m disso, veja que g√™nero apareceu 2 vezes na mesma frase, dessa forma sua contagem √© atualizada na frase atual, com seu token de contexto "textos" com 2 ocorr√™ncias.

N√£o considerou-se que os pr√≥prios tokens centrais aparecessem em seus tokens de contexto (no caso "g√™nero" n√£o foi considerado um token de contexto para "g√™nero", por mais que aparecesse dentro da janela de contexto).
A l√≥gica do filtro nas frases foi validado por an√°lise de respostas no f√≥rum Stack Overflow dispon√≠vel no link: [How is Word2Vec min_count applied](https://stackoverflow.com/questions/50723303/how-is-word2vec-min-count-applied).


### Observa√ß√µes e Melhorias

O projeto SKINNER ainda est√° em fase de testes, totalmente funcional, mas n√£o totalmente otimizado. Ainda pode-se melhor√°-lo da seguinte forma:
- Filtro para n√£o pesquisar palavras fora do vocabul√°rio;
- Exibi√ß√£o, no PDF, apenas das cole√ß√µes e trabalhos que tiveram contribui√ß√£o, de fato, na constru√ß√£o de contexto para determinado token (atualmente a cole√ß√£o/trabalho aparece com 0% e um espa√ßo vazio);
- Ordena√ß√£o da maior porcentagem para a menor porcentagem de contribui√ß√£o na listagem de cole√ß√µes e na listagem de trabalhos.
- Possibilidade de gera√ß√£o apenas de arquivo HTML com navega√ß√£o via menu lateral como resultado final, pois o HTML √© gerado muito mais r√°pido que o arquivo PDF.

Embora exista a possibilidade da realiza√ß√£o de tais melhorias, √© importante destacar que este projeto teve como principal objetivo acender uma luz dentro da "caixa-preta" que assombra o processo de constru√ß√£o de modelos de intelig√™ncia artificial, tendo como maior foco, especificamente, modelos de processamento de linguagem natural. 
Dito isso, pode-se dizer que o resultado atual do SKINNER j√° mostrou grandes potencialidades na busca por refer√™ncias dentro do corpus de textos utilizados diante de resultados obtidos por tais modelos.

## Desenvolvedor

- Igor Caetano de Souza *[(Perfil GitHub)](https://github.com/IgorCaetano)*
